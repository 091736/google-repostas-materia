{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/091736/google-repostas-materia/blob/main/fooocus_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VjYy0F2gZIPR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fda0cbb-9833-4376-a319-de6298b73271"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pygit2==1.15.1\n",
            "  Downloading pygit2-1.15.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: cffi>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from pygit2==1.15.1) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.16.0->pygit2==1.15.1) (2.22)\n",
            "Downloading pygit2-1.15.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/5.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.3/5.1 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m4.9/5.1 MB\u001b[0m \u001b[31m70.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m55.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pygit2\n",
            "  Attempting uninstall: pygit2\n",
            "    Found existing installation: pygit2 1.18.0\n",
            "    Uninstalling pygit2-1.18.0:\n",
            "      Successfully uninstalled pygit2-1.18.0\n",
            "Successfully installed pygit2-1.15.1\n",
            "/content\n",
            "Cloning into 'Fooocus'...\n",
            "remote: Enumerating objects: 6725, done.\u001b[K\n",
            "remote: Total 6725 (delta 0), reused 0 (delta 0), pack-reused 6725 (from 1)\u001b[K\n",
            "Receiving objects: 100% (6725/6725), 33.33 MiB | 16.57 MiB/s, done.\n",
            "Resolving deltas: 100% (3854/3854), done.\n",
            "/content/Fooocus\n",
            "Already up-to-date\n",
            "Update succeeded.\n",
            "[System ARGV] ['entry_with_update.py', '--share', '--always-high-vram']\n",
            "Python 3.11.12 (main, Apr  9 2025, 08:55:54) [GCC 11.4.0]\n",
            "Fooocus version: 2.5.5\n",
            "Error checking version for torchsde: No package metadata was found for torchsde\n",
            "Installing requirements\n",
            "[Cleanup] Attempting to delete content of temp dir /tmp/fooocus\n",
            "[Cleanup] Cleanup successful\n",
            "Downloading: \"https://huggingface.co/lllyasviel/misc/resolve/main/xlvaeapp.pth\" to /content/Fooocus/models/vae_approx/xlvaeapp.pth\n",
            "\n",
            "100% 209k/209k [00:00<00:00, 9.98MB/s]\n",
            "Downloading: \"https://huggingface.co/lllyasviel/misc/resolve/main/vaeapp_sd15.pt\" to /content/Fooocus/models/vae_approx/vaeapp_sd15.pth\n",
            "\n",
            "100% 209k/209k [00:00<00:00, 4.13MB/s]\n",
            "Downloading: \"https://huggingface.co/mashb1t/misc/resolve/main/xl-to-v1_interposer-v4.0.safetensors\" to /content/Fooocus/models/vae_approx/xl-to-v1_interposer-v4.0.safetensors\n",
            "\n",
            "100% 5.40M/5.40M [00:00<00:00, 45.9MB/s]\n",
            "Downloading: \"https://huggingface.co/lllyasviel/misc/resolve/main/fooocus_expansion.bin\" to /content/Fooocus/models/prompt_expansion/fooocus_expansion/pytorch_model.bin\n",
            "\n",
            "100% 335M/335M [00:01<00:00, 211MB/s]\n",
            "Downloading: \"https://huggingface.co/lllyasviel/fav_models/resolve/main/fav/juggernautXL_v8Rundiffusion.safetensors\" to /content/Fooocus/models/checkpoints/juggernautXL_v8Rundiffusion.safetensors\n",
            "\n",
            "100% 6.62G/6.62G [00:43<00:00, 164MB/s]\n",
            "Downloading: \"https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/sd_xl_offset_example-lora_1.0.safetensors\" to /content/Fooocus/models/loras/sd_xl_offset_example-lora_1.0.safetensors\n",
            "\n",
            "100% 47.3M/47.3M [00:00<00:00, 302MB/s]\n",
            "Total VRAM 15095 MB, total RAM 12978 MB\n",
            "Set vram state to: HIGH_VRAM\n",
            "Always offload VRAM\n",
            "Device: cuda:0 Tesla T4 : native\n",
            "VAE dtype: torch.float32\n",
            "Using pytorch cross attention\n",
            "Refiner unloaded.\n",
            "IMPORTANT: You are using gradio version 3.41.2, however version 4.44.1 is available, please upgrade.\n",
            "--------\n",
            "Running on local URL:  http://127.0.0.1:7865\n",
            "Running on public URL: https://8f8d0e955c5a3036d3.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n",
            "model_type EPS\n",
            "UNet ADM Dimension 2816\n",
            "Using pytorch attention in VAE\n",
            "Working with z of shape (1, 4, 32, 32) = 4096 dimensions.\n",
            "Using pytorch attention in VAE\n",
            "extra {'cond_stage_model.clip_l.text_projection', 'cond_stage_model.clip_l.logit_scale'}\n",
            "left over keys: dict_keys(['cond_stage_model.clip_l.transformer.text_model.embeddings.position_ids'])\n",
            "loaded straight to GPU\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "Base model loaded: /content/Fooocus/models/checkpoints/juggernautXL_v8Rundiffusion.safetensors\n",
            "VAE loaded: None\n",
            "Request to load LoRAs [('sd_xl_offset_example-lora_1.0.safetensors', 0.1)] for model [/content/Fooocus/models/checkpoints/juggernautXL_v8Rundiffusion.safetensors].\n",
            "Loaded LoRA [/content/Fooocus/models/loras/sd_xl_offset_example-lora_1.0.safetensors] for UNet [/content/Fooocus/models/checkpoints/juggernautXL_v8Rundiffusion.safetensors] with 788 keys at weight 0.1.\n",
            "Fooocus V2 Expansion: Vocab with 642 words.\n",
            "Fooocus Expansion engine loaded for cuda:0, use_fp16 = True.\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.60 seconds\n",
            "2025-05-07 01:25:46.059942: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1746581146.301039    3658 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1746581146.369225    3658 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-05-07 01:25:46.871054: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Started worker with PID 2591\n",
            "App started successful. Use the app with http://127.0.0.1:7865/ or 127.0.0.1:7865 or https://8f8d0e955c5a3036d3.gradio.live\n",
            "Loaded preset: /content/Fooocus/presets/realistic.json\n",
            "Downloading: \"https://huggingface.co/lllyasviel/fav_models/resolve/main/fav/realisticStockPhoto_v20.safetensors\" to /content/Fooocus/models/checkpoints/realisticStockPhoto_v20.safetensors\n",
            "\n",
            "100% 6.46G/6.46G [01:36<00:00, 71.5MB/s]\n",
            "Downloading: \"https://huggingface.co/mashb1t/fav_models/resolve/main/fav/SDXL_FILM_PHOTOGRAPHY_STYLE_V1.safetensors\" to /content/Fooocus/models/loras/SDXL_FILM_PHOTOGRAPHY_STYLE_V1.safetensors\n",
            "\n",
            "100% 870M/870M [00:04<00:00, 194MB/s]\n",
            "Loaded preset: /content/Fooocus/presets/realistic.json\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 5587922065246800893\n",
            "[Parameters] CFG = 3\n",
            "[Fooocus] Downloading control models ...\n",
            "Downloading: \"https://huggingface.co/lllyasviel/misc/resolve/main/clip_vision_vit_h.safetensors\" to /content/Fooocus/models/clip_vision/clip_vision_vit_h.safetensors\n",
            "\n",
            "100% 1.84G/1.84G [00:21<00:00, 92.6MB/s]\n",
            "Downloading: \"https://huggingface.co/lllyasviel/misc/resolve/main/fooocus_ip_negative.safetensors\" to /content/Fooocus/models/controlnet/fooocus_ip_negative.safetensors\n",
            "\n",
            "100% 64.1k/64.1k [00:00<00:00, 2.30MB/s]\n",
            "Downloading: \"https://huggingface.co/lllyasviel/misc/resolve/main/ip-adapter-plus-face_sdxl_vit-h.bin\" to /content/Fooocus/models/controlnet/ip-adapter-plus-face_sdxl_vit-h.bin\n",
            "\n",
            "100% 967M/967M [00:09<00:00, 109MB/s]\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 30\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "model_type EPS\n",
            "UNet ADM Dimension 2816\n",
            "Using pytorch attention in VAE\n",
            "Working with z of shape (1, 4, 32, 32) = 4096 dimensions.\n",
            "Using pytorch attention in VAE\n",
            "extra {'cond_stage_model.clip_l.text_projection', 'cond_stage_model.clip_l.logit_scale'}\n",
            "left over keys: dict_keys(['cond_stage_model.clip_l.transformer.text_model.embeddings.position_ids'])\n",
            "loaded straight to GPU\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.82 seconds\n",
            "Base model loaded: /content/Fooocus/models/checkpoints/realisticStockPhoto_v20.safetensors\n",
            "VAE loaded: None\n",
            "Request to load LoRAs [('SDXL_FILM_PHOTOGRAPHY_STYLE_V1.safetensors', 0.25)] for model [/content/Fooocus/models/checkpoints/realisticStockPhoto_v20.safetensors].\n",
            "Loaded LoRA [/content/Fooocus/models/loras/SDXL_FILM_PHOTOGRAPHY_STYLE_V1.safetensors] for UNet [/content/Fooocus/models/checkpoints/realisticStockPhoto_v20.safetensors] with 722 keys at weight 0.25.\n",
            "Loaded LoRA [/content/Fooocus/models/loras/SDXL_FILM_PHOTOGRAPHY_STYLE_V1.safetensors] for CLIP [/content/Fooocus/models/checkpoints/realisticStockPhoto_v20.safetensors] with 264 keys at weight 0.25.\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.56 seconds\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] RAW photo, ultra-realistic DSLR photo, full body of a gothic female model inspired by Billie Eilish, standing, cinematic lighting, gothic atmosphere, sharp symmetrical face, neutral expression, expressive, very detailed, intricate, cool, highly educated, deep light, excellent composition, innocent, stunning, aesthetic, rich vibrant colors, symmetry\n",
            "[Fooocus] Preparing Fooocus text #2 ...\n",
            "[Prompt Expansion] RAW photo, ultra-realistic DSLR photo, full body of a gothic female model inspired by Billie Eilish, standing, cinematic lighting, gothic atmosphere, sharp symmetrical face, neutral expression, expressive, very detailed, intricate, cool, highly depicted, extremely holy, radiant light, dramatic background, rich vibrant colors, beautiful professional quality\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.12 seconds\n",
            "[Fooocus] Encoding positive #2 ...\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Encoding negative #2 ...\n",
            "[Fooocus] Image processing ...\n",
            "Downloading: \"https://github.com/xinntao/facexlib/releases/download/v0.1.0/detection_Resnet50_Final.pth\" to /content/Fooocus/models/controlnet/detection_Resnet50_Final.pth\n",
            "\n",
            "100% 104M/104M [00:00<00:00, 305MB/s] \n",
            "Downloading: \"https://github.com/xinntao/facexlib/releases/download/v0.2.2/parsing_parsenet.pth\" to /content/Fooocus/models/controlnet/parsing_parsenet.pth\n",
            "\n",
            "100% 81.4M/81.4M [00:00<00:00, 279MB/s]\n",
            "Detected 1 faces\n",
            "Requested to load CLIPVisionModelWithProjection\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.71 seconds\n",
            "Requested to load Resampler\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.43 seconds\n",
            "Requested to load To_KV\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.28 seconds\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (1152, 896)\n",
            "Preparation time: 86.89 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/2 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.73 seconds\n",
            "100% 60/60 [01:04<00:00,  1.07s/it]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.27 seconds\n",
            "[Fooocus] Saving image 1/2 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-05-07/log.html\n",
            "Generating and saving time: 68.85 seconds\n",
            "[Fooocus] Preparing task 2/2 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.76 seconds\n",
            "100% 60/60 [01:05<00:00,  1.08s/it]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.27 seconds\n",
            "[Fooocus] Saving image 2/2 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-05-07/log.html\n",
            "Generating and saving time: 68.61 seconds\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 137.46 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 224.41 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.19 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 8176210801639219630\n",
            "[Parameters] CFG = 3\n",
            "[Fooocus] Downloading control models ...\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 30\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] RAW photo, ultra-realistic DSLR photo, full body of a gothic female model inspired by Billie Eilish, sitting on a metal bench in an urban square, one leg crossed over the other, contemplative expression, cinematic lighting, soft shadows, bright colors, sunny, clear, color, detailed, intricate, innocent, confident, artistic, beautiful\n",
            "[Fooocus] Preparing Fooocus text #2 ...\n",
            "[Prompt Expansion] RAW photo, ultra-realistic DSLR photo, full body of a gothic female model inspired by Billie Eilish, sitting on a metal bench in an urban square, one leg crossed over the other, contemplative expression, cinematic lighting, soft shadows, cozy atmosphere, beautiful detailed intricate complex highly artistic color real, lovely grand delicate fine detail, flowing\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.16 seconds\n",
            "[Fooocus] Encoding positive #2 ...\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Encoding negative #2 ...\n",
            "[Fooocus] Image processing ...\n",
            "Detected 1 faces\n",
            "Requested to load CLIPVisionModelWithProjection\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.77 seconds\n",
            "Requested to load Resampler\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.47 seconds\n",
            "Requested to load To_KV\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.26 seconds\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (1152, 896)\n",
            "Preparation time: 7.06 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/2 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.81 seconds\n",
            "100% 60/60 [01:06<00:00,  1.11s/it]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.33 seconds\n",
            "[Fooocus] Saving image 1/2 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-05-07/log.html\n",
            "Generating and saving time: 70.09 seconds\n",
            "[Fooocus] Preparing task 2/2 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.76 seconds\n",
            "100% 60/60 [01:05<00:00,  1.09s/it]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.25 seconds\n",
            "[Fooocus] Saving image 2/2 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-05-07/log.html\n",
            "Generating and saving time: 68.85 seconds\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 138.95 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 146.06 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.06 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 8176210801639219630\n",
            "[Parameters] CFG = 3\n",
            "[Fooocus] Downloading upscale models ...\n",
            "Downloading: \"https://huggingface.co/lllyasviel/misc/resolve/main/fooocus_upscaler_s409985e5.bin\" to /content/Fooocus/models/upscale_models/fooocus_upscaler_s409985e5.bin\n",
            "\n",
            "100% 32.1M/32.1M [00:00<00:00, 280MB/s]\n",
            "[Fooocus] Downloading inpainter ...\n",
            "Downloading: \"https://huggingface.co/lllyasviel/fooocus_inpaint/resolve/main/fooocus_inpaint_head.pth\" to /content/Fooocus/models/inpaint/fooocus_inpaint_head.pth\n",
            "\n",
            "100% 51.4k/51.4k [00:00<00:00, 6.20MB/s]\n",
            "Downloading: \"https://huggingface.co/lllyasviel/fooocus_inpaint/resolve/main/inpaint_v26.fooocus.patch\" to /content/Fooocus/models/inpaint/inpaint_v26.fooocus.patch\n",
            "\n",
            "100% 1.23G/1.23G [00:29<00:00, 44.9MB/s]\n",
            "[Inpaint] Current inpaint model is /content/Fooocus/models/inpaint/inpaint_v26.fooocus.patch\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 48\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Synthetic Refiner Activated\n",
            "Synthetic Refiner Activated\n",
            "Request to load LoRAs [('SDXL_FILM_PHOTOGRAPHY_STYLE_V1.safetensors', 0.25), ('/content/Fooocus/models/inpaint/inpaint_v26.fooocus.patch', 1.0)] for model [/content/Fooocus/models/checkpoints/realisticStockPhoto_v20.safetensors].\n",
            "Loaded LoRA [/content/Fooocus/models/loras/SDXL_FILM_PHOTOGRAPHY_STYLE_V1.safetensors] for UNet [/content/Fooocus/models/checkpoints/realisticStockPhoto_v20.safetensors] with 722 keys at weight 0.25.\n",
            "Loaded LoRA [/content/Fooocus/models/loras/SDXL_FILM_PHOTOGRAPHY_STYLE_V1.safetensors] for CLIP [/content/Fooocus/models/checkpoints/realisticStockPhoto_v20.safetensors] with 264 keys at weight 0.25.\n",
            "Loaded LoRA [/content/Fooocus/models/inpaint/inpaint_v26.fooocus.patch] for UNet [/content/Fooocus/models/checkpoints/realisticStockPhoto_v20.safetensors] with 960 keys at weight 1.0.\n",
            "Request to load LoRAs [('SDXL_FILM_PHOTOGRAPHY_STYLE_V1.safetensors', 0.25)] for model [/content/Fooocus/models/checkpoints/realisticStockPhoto_v20.safetensors].\n",
            "Loaded LoRA [/content/Fooocus/models/loras/SDXL_FILM_PHOTOGRAPHY_STYLE_V1.safetensors] for UNet [/content/Fooocus/models/checkpoints/realisticStockPhoto_v20.safetensors] with 722 keys at weight 0.25.\n",
            "Requested to load SDXLClipModel\n",
            "Loading 1 new model\n",
            "unload clone 1\n",
            "[Fooocus Model Management] Moving model(s) has taken 2.42 seconds\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] RAW photo, ultra-realistic DSLR photo, full body of a gothic female model inspired by Billie Eilish, sitting on a metal bench in an urban square, one leg crossed over the other, contemplative expression, cinematic lighting, soft shadows, bright colors, sunny, clear, color, detailed, intricate, innocent, confident, artistic, beautiful\n",
            "[Fooocus] Preparing Fooocus text #2 ...\n",
            "[Prompt Expansion] RAW photo, ultra-realistic DSLR photo, full body of a gothic female model inspired by Billie Eilish, sitting on a metal bench in an urban square, one leg crossed over the other, contemplative expression, cinematic lighting, soft shadows, cozy atmosphere, beautiful detailed intricate complex highly artistic color real, lovely grand delicate fine detail, flowing\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.18 seconds\n",
            "[Fooocus] Encoding positive #2 ...\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Encoding negative #2 ...\n",
            "[Fooocus] Image processing ...\n",
            "Upscaling image with shape (713, 713, 3) ...\n",
            "[Fooocus] VAE Inpaint encoding ...\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.61 seconds\n",
            "[Fooocus] VAE encoding ...\n",
            "Final resolution is (896, 1152), latent is (1024, 1024).\n",
            "[Parameters] Denoising Strength = 1\n",
            "[Parameters] Initial Latent shape: torch.Size([1, 4, 128, 128])\n",
            "Preparation time: 54.78 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/2 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 5.46 seconds\n",
            " 80% 48/60 [00:52<00:12,  1.07s/it]Requested to load SDXL\n",
            "Loading 1 new model\n",
            "unload clone 0\n",
            "[Fooocus Model Management] Moving model(s) has taken 3.29 seconds\n",
            "Refiner Swapped\n",
            "100% 60/60 [01:07<00:00,  1.13s/it]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.28 seconds\n",
            "[Fooocus] Saving image 1/2 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-05-07/log.html\n",
            "Generating and saving time: 76.48 seconds\n",
            "[Fooocus] Preparing task 2/2 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.57 seconds\n",
            " 80% 48/60 [00:52<00:13,  1.09s/it]Requested to load SDXL\n",
            "Loading 1 new model\n",
            "unload clone 0\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.58 seconds\n",
            "Refiner Swapped\n",
            "100% 60/60 [01:05<00:00,  1.09s/it]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.27 seconds\n",
            "[Fooocus] Saving image 2/2 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-05-07/log.html\n",
            "Generating and saving time: 69.68 seconds\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 146.16 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 201.00 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.57 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 8176210801639219630\n",
            "[Parameters] CFG = 3\n",
            "[Fooocus] Downloading control models ...\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 30\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "Request to load LoRAs [('SDXL_FILM_PHOTOGRAPHY_STYLE_V1.safetensors', 0.25)] for model [/content/Fooocus/models/checkpoints/realisticStockPhoto_v20.safetensors].\n",
            "Loaded LoRA [/content/Fooocus/models/loras/SDXL_FILM_PHOTOGRAPHY_STYLE_V1.safetensors] for UNet [/content/Fooocus/models/checkpoints/realisticStockPhoto_v20.safetensors] with 722 keys at weight 0.25.\n",
            "Loaded LoRA [/content/Fooocus/models/loras/SDXL_FILM_PHOTOGRAPHY_STYLE_V1.safetensors] for CLIP [/content/Fooocus/models/checkpoints/realisticStockPhoto_v20.safetensors] with 264 keys at weight 0.25.\n",
            "Requested to load SDXLClipModel\n",
            "Loading 1 new model\n",
            "unload clone 1\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.15 seconds\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] RAW photo, ultra-realistic DSLR photo, full body of a gothic female model inspired by Billie Eilish, sitting on a metal bench in an urban square, one leg crossed over the other, contemplative expression, cinematic lighting, soft shadows, bright colors, sunny, clear, color, detailed, intricate, innocent, confident, artistic, beautiful\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.17 seconds\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Image processing ...\n",
            "Detected 1 faces\n",
            "Requested to load CLIPVisionModelWithProjection\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.76 seconds\n",
            "Requested to load Resampler\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.48 seconds\n",
            "Requested to load To_KV\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.29 seconds\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (1152, 896)\n",
            "Preparation time: 7.99 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/1 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.83 seconds\n",
            "100% 60/60 [01:06<00:00,  1.11s/it]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.32 seconds\n",
            "[Fooocus] Saving image 1/1 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-05-07/log.html\n",
            "Generating and saving time: 70.31 seconds\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 70.31 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 78.33 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.98 seconds\n",
            "Enter Hyper-SD mode.\n",
            "[Fooocus] Downloading Hyper-SD components ...\n",
            "Downloading: \"https://huggingface.co/mashb1t/misc/resolve/main/sdxl_hyper_sd_4step_lora.safetensors\" to /content/Fooocus/models/loras/sdxl_hyper_sd_4step_lora.safetensors\n",
            "\n",
            "100% 751M/751M [00:21<00:00, 36.1MB/s]\n",
            "[Parameters] Adaptive CFG = 1.0\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 0.0\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.0 : 1.0 : 0.0\n",
            "[Parameters] Seed = 8176210801639219630\n",
            "[Parameters] CFG = 1.0\n",
            "[Fooocus] Downloading control models ...\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_sde_gpu - karras\n",
            "[Parameters] Steps = 4 - 4\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "Request to load LoRAs [('SDXL_FILM_PHOTOGRAPHY_STYLE_V1.safetensors', 0.25), ('sdxl_hyper_sd_4step_lora.safetensors', 0.8)] for model [/content/Fooocus/models/checkpoints/realisticStockPhoto_v20.safetensors].\n",
            "Loaded LoRA [/content/Fooocus/models/loras/SDXL_FILM_PHOTOGRAPHY_STYLE_V1.safetensors] for UNet [/content/Fooocus/models/checkpoints/realisticStockPhoto_v20.safetensors] with 722 keys at weight 0.25.\n",
            "Loaded LoRA [/content/Fooocus/models/loras/SDXL_FILM_PHOTOGRAPHY_STYLE_V1.safetensors] for CLIP [/content/Fooocus/models/checkpoints/realisticStockPhoto_v20.safetensors] with 264 keys at weight 0.25.\n",
            "Loaded LoRA [/content/Fooocus/models/loras/sdxl_hyper_sd_4step_lora.safetensors] for UNet [/content/Fooocus/models/checkpoints/realisticStockPhoto_v20.safetensors] with 788 keys at weight 0.8.\n",
            "Requested to load SDXLClipModel\n",
            "Loading 1 new model\n",
            "unload clone 1\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.09 seconds\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] RAW photo, ultra-realistic DSLR photo, full body of a gothic female model inspired by Billie Eilish, sitting on a metal bench in an urban square, one leg crossed over the other, contemplative expression, cinematic lighting, soft shadows, bright colors, sunny, clear, color, detailed, intricate, innocent, confident, artistic, beautiful\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.12 seconds\n",
            "[Fooocus] Image processing ...\n",
            "Detected 1 faces\n",
            "Requested to load CLIPVisionModelWithProjection\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.77 seconds\n",
            "Requested to load Resampler\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.48 seconds\n",
            "Requested to load To_KV\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.27 seconds\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (1152, 896)\n",
            "Preparation time: 28.93 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/1 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.40 seconds\n",
            "100% 4/4 [00:03<00:00,  1.17it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.27 seconds\n",
            "[Fooocus] Saving image 1/1 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-05-07/log.html\n",
            "Generating and saving time: 7.74 seconds\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 7.74 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 36.70 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.90 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 8176210801639219630\n",
            "[Parameters] CFG = 3\n",
            "[Fooocus] Downloading control models ...\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 60\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "model_type EPS\n",
            "UNet ADM Dimension 2816\n",
            "Using pytorch attention in VAE\n",
            "Working with z of shape (1, 4, 32, 32) = 4096 dimensions.\n",
            "Using pytorch attention in VAE\n",
            "extra {'cond_stage_model.clip_l.text_projection', 'cond_stage_model.clip_l.logit_scale'}\n",
            "left over keys: dict_keys(['cond_stage_model.clip_l.transformer.text_model.embeddings.position_ids'])\n",
            "loaded straight to GPU\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.72 seconds\n",
            "Refiner model loaded: /content/Fooocus/models/checkpoints/juggernautXL_v8Rundiffusion.safetensors\n",
            "Request to load LoRAs [('SDXL_FILM_PHOTOGRAPHY_STYLE_V1.safetensors', 0.25)] for model [/content/Fooocus/models/checkpoints/realisticStockPhoto_v20.safetensors].\n",
            "Loaded LoRA [/content/Fooocus/models/loras/SDXL_FILM_PHOTOGRAPHY_STYLE_V1.safetensors] for UNet [/content/Fooocus/models/checkpoints/realisticStockPhoto_v20.safetensors] with 722 keys at weight 0.25.\n",
            "Loaded LoRA [/content/Fooocus/models/loras/SDXL_FILM_PHOTOGRAPHY_STYLE_V1.safetensors] for CLIP [/content/Fooocus/models/checkpoints/realisticStockPhoto_v20.safetensors] with 264 keys at weight 0.25.\n",
            "Request to load LoRAs [('SDXL_FILM_PHOTOGRAPHY_STYLE_V1.safetensors', 0.25)] for model [/content/Fooocus/models/checkpoints/juggernautXL_v8Rundiffusion.safetensors].\n",
            "Loaded LoRA [/content/Fooocus/models/loras/SDXL_FILM_PHOTOGRAPHY_STYLE_V1.safetensors] for UNet [/content/Fooocus/models/checkpoints/juggernautXL_v8Rundiffusion.safetensors] with 722 keys at weight 0.25.\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "[Fooocus Model Management] Moving model(s) has taken 2.01 seconds\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.25 seconds\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Image processing ...\n",
            "Detected 1 faces\n",
            "Requested to load CLIPVisionModelWithProjection\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.75 seconds\n",
            "Requested to load Resampler\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.46 seconds\n",
            "Requested to load To_KV\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.26 seconds\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (1152, 896)\n",
            "Preparation time: 45.62 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/1 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 2.14 seconds\n",
            "  0% 0/60 [00:01<?, ?it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Fooocus/modules/async_worker.py\", line 1471, in worker\n",
            "    handler(task)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/modules/async_worker.py\", line 1286, in handler\n",
            "    imgs, img_paths, current_progress = process_task(all_steps, async_task, callback, controlnet_canny_path,\n",
            "                                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/modules/async_worker.py\", line 295, in process_task\n",
            "    imgs = pipeline.process_diffusion(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/modules/default_pipeline.py\", line 379, in process_diffusion\n",
            "    sampled_latent = core.ksampler(\n",
            "                     ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/modules/core.py\", line 310, in ksampler\n",
            "    samples = ldm_patched.modules.sample.sample(model,\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/ldm_patched/modules/sample.py\", line 100, in sample\n",
            "    samples = sampler.sample(noise, positive_copy, negative_copy, cfg=cfg, latent_image=latent_image, start_step=start_step, last_step=last_step, force_full_denoise=force_full_denoise, denoise_mask=noise_mask, sigmas=sigmas, callback=callback, disable_pbar=disable_pbar, seed=seed)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/ldm_patched/modules/samplers.py\", line 712, in sample\n",
            "    return sample(self.model, noise, positive, negative, cfg, self.device, sampler, sigmas, self.model_options, latent_image=latent_image, denoise_mask=denoise_mask, callback=callback, disable_pbar=disable_pbar, seed=seed)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/modules/sample_hijack.py\", line 158, in sample_hacked\n",
            "    samples = sampler.sample(model_wrap, sigmas, extra_args, callback_wrap, noise, latent_image, denoise_mask, disable_pbar)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/ldm_patched/modules/samplers.py\", line 557, in sample\n",
            "    samples = self.sampler_function(model_k, noise, sigmas, extra_args=extra_args, callback=k_callback, disable=disable_pbar, **self.extra_options)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/ldm_patched/k_diffusion/sampling.py\", line 701, in sample_dpmpp_2m_sde_gpu\n",
            "    return sample_dpmpp_2m_sde(model, x, sigmas, extra_args=extra_args, callback=callback, disable=disable, eta=eta, s_noise=s_noise, noise_sampler=noise_sampler, solver_type=solver_type)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/ldm_patched/k_diffusion/sampling.py\", line 613, in sample_dpmpp_2m_sde\n",
            "    denoised = model(x, sigmas[i] * s_in, **extra_args)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/modules/patch.py\", line 321, in patched_KSamplerX0Inpaint_forward\n",
            "    out = self.inner_model(x, sigma,\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/ldm_patched/modules/samplers.py\", line 271, in forward\n",
            "    return self.apply_model(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/ldm_patched/modules/samplers.py\", line 268, in apply_model\n",
            "    out = sampling_function(self.inner_model, x, timestep, uncond, cond, cond_scale, model_options=model_options, seed=seed)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/modules/patch.py\", line 244, in patched_sampling_function\n",
            "    positive_eps_degraded = anisotropic.adaptive_anisotropic_filter(x=positive_eps, g=positive_x0)\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/modules/anisotropic.py\", line 135, in adaptive_anisotropic_filter\n",
            "    y = _bilateral_blur(x, guidance,\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/modules/anisotropic.py\", line 103, in _bilateral_blur\n",
            "    color_distance_sq = diff.abs().sum(1, keepdim=True).square()\n",
            "                        ^^^^^^^^^^\n",
            "torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 42.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 8.12 MiB is free. Process 29332 has 14.73 GiB memory in use. Of the allocated memory 14.13 GiB is allocated by PyTorch, and 476.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Total time: 49.08 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.7 : 0.3\n",
            "[Parameters] Seed = 8176210801639219630\n",
            "[Parameters] CFG = 3\n",
            "[Fooocus] Downloading control models ...\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 60\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.10 seconds\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.15 seconds\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Image processing ...\n",
            "Detected 1 faces\n",
            "Requested to load CLIPVisionModelWithProjection\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.76 seconds\n",
            "Requested to load Resampler\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.46 seconds\n",
            "Requested to load To_KV\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.26 seconds\n",
            "FreeU is enabled!\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (1152, 896)\n",
            "Preparation time: 7.34 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/1 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.79 seconds\n",
            "  0% 0/60 [00:01<?, ?it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Fooocus/modules/async_worker.py\", line 1471, in worker\n",
            "    handler(task)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/modules/async_worker.py\", line 1286, in handler\n",
            "    imgs, img_paths, current_progress = process_task(all_steps, async_task, callback, controlnet_canny_path,\n",
            "                                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/modules/async_worker.py\", line 295, in process_task\n",
            "    imgs = pipeline.process_diffusion(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/modules/default_pipeline.py\", line 379, in process_diffusion\n",
            "    sampled_latent = core.ksampler(\n",
            "                     ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/modules/core.py\", line 310, in ksampler\n",
            "    samples = ldm_patched.modules.sample.sample(model,\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/ldm_patched/modules/sample.py\", line 100, in sample\n",
            "    samples = sampler.sample(noise, positive_copy, negative_copy, cfg=cfg, latent_image=latent_image, start_step=start_step, last_step=last_step, force_full_denoise=force_full_denoise, denoise_mask=noise_mask, sigmas=sigmas, callback=callback, disable_pbar=disable_pbar, seed=seed)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/ldm_patched/modules/samplers.py\", line 712, in sample\n",
            "    return sample(self.model, noise, positive, negative, cfg, self.device, sampler, sigmas, self.model_options, latent_image=latent_image, denoise_mask=denoise_mask, callback=callback, disable_pbar=disable_pbar, seed=seed)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/modules/sample_hijack.py\", line 158, in sample_hacked\n",
            "    samples = sampler.sample(model_wrap, sigmas, extra_args, callback_wrap, noise, latent_image, denoise_mask, disable_pbar)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/ldm_patched/modules/samplers.py\", line 557, in sample\n",
            "    samples = self.sampler_function(model_k, noise, sigmas, extra_args=extra_args, callback=k_callback, disable=disable_pbar, **self.extra_options)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/ldm_patched/k_diffusion/sampling.py\", line 701, in sample_dpmpp_2m_sde_gpu\n",
            "    return sample_dpmpp_2m_sde(model, x, sigmas, extra_args=extra_args, callback=callback, disable=disable, eta=eta, s_noise=s_noise, noise_sampler=noise_sampler, solver_type=solver_type)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/ldm_patched/k_diffusion/sampling.py\", line 613, in sample_dpmpp_2m_sde\n",
            "    denoised = model(x, sigmas[i] * s_in, **extra_args)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/modules/patch.py\", line 321, in patched_KSamplerX0Inpaint_forward\n",
            "    out = self.inner_model(x, sigma,\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/ldm_patched/modules/samplers.py\", line 271, in forward\n",
            "    return self.apply_model(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/ldm_patched/modules/samplers.py\", line 268, in apply_model\n",
            "    out = sampling_function(self.inner_model, x, timestep, uncond, cond, cond_scale, model_options=model_options, seed=seed)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/modules/patch.py\", line 237, in patched_sampling_function\n",
            "    positive_x0, negative_x0 = calc_cond_uncond_batch(model, cond, uncond, x, timestep, model_options)\n",
            "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/ldm_patched/modules/samplers.py\", line 222, in calc_cond_uncond_batch\n",
            "    output = model.apply_model(input_x, timestep_, **c).chunk(batch_chunks)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/ldm_patched/modules/model_base.py\", line 85, in apply_model\n",
            "    model_output = self.diffusion_model(xc, t, context=context, control=control, transformer_options=transformer_options, **extra_conds).float()\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/modules/patch.py\", line 437, in patched_unet_forward\n",
            "    h = forward_timestep_embed(module, h, emb, context, transformer_options, output_shape, time_context=time_context, num_video_frames=num_video_frames, image_only_indicator=image_only_indicator)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/ldm_patched/ldm/modules/diffusionmodules/openaimodel.py\", line 43, in forward_timestep_embed\n",
            "    x = layer(x, context, transformer_options)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/ldm_patched/ldm/modules/attention.py\", line 613, in forward\n",
            "    x = block(x, context=context[i], transformer_options=transformer_options)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/ldm_patched/ldm/modules/attention.py\", line 440, in forward\n",
            "    return checkpoint(self._forward, (x, context, transformer_options), self.parameters(), self.checkpoint)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/ldm_patched/ldm/modules/diffusionmodules/util.py\", line 189, in checkpoint\n",
            "    return func(*inputs)\n",
            "           ^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/ldm_patched/ldm/modules/attention.py\", line 550, in _forward\n",
            "    x = self.ff(self.norm3(x))\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/ldm_patched/ldm/modules/attention.py\", line 82, in forward\n",
            "    return self.net(x)\n",
            "           ^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\", line 250, in forward\n",
            "    input = module(input)\n",
            "            ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/ldm_patched/ldm/modules/attention.py\", line 62, in forward\n",
            "    return x * F.gelu(gate)\n",
            "           ~~^~~~~~~~~~~~~~\n",
            "torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 20.12 MiB is free. Process 29332 has 14.72 GiB memory in use. Of the allocated memory 14.16 GiB is allocated by PyTorch, and 427.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Total time: 9.31 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.7 : 0.3\n",
            "[Parameters] Seed = 8176210801639219630\n",
            "[Parameters] CFG = 3\n",
            "[Fooocus] Downloading control models ...\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 60\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.91 seconds\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.11 seconds\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Image processing ...\n",
            "Detected 1 faces\n",
            "Requested to load CLIPVisionModelWithProjection\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.80 seconds\n",
            "Requested to load Resampler\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.42 seconds\n",
            "Requested to load To_KV\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.25 seconds\n",
            "FreeU is enabled!\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (1152, 896)\n",
            "Preparation time: 7.07 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/1 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.82 seconds\n",
            "  0% 0/60 [00:00<?, ?it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Fooocus/modules/async_worker.py\", line 1471, in worker\n",
            "    handler(task)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/modules/async_worker.py\", line 1286, in handler\n",
            "    imgs, img_paths, current_progress = process_task(all_steps, async_task, callback, controlnet_canny_path,\n",
            "                                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/modules/async_worker.py\", line 295, in process_task\n",
            "    imgs = pipeline.process_diffusion(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/modules/default_pipeline.py\", line 379, in process_diffusion\n",
            "    sampled_latent = core.ksampler(\n",
            "                     ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/modules/core.py\", line 310, in ksampler\n",
            "    samples = ldm_patched.modules.sample.sample(model,\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/ldm_patched/modules/sample.py\", line 100, in sample\n",
            "    samples = sampler.sample(noise, positive_copy, negative_copy, cfg=cfg, latent_image=latent_image, start_step=start_step, last_step=last_step, force_full_denoise=force_full_denoise, denoise_mask=noise_mask, sigmas=sigmas, callback=callback, disable_pbar=disable_pbar, seed=seed)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/ldm_patched/modules/samplers.py\", line 712, in sample\n",
            "    return sample(self.model, noise, positive, negative, cfg, self.device, sampler, sigmas, self.model_options, latent_image=latent_image, denoise_mask=denoise_mask, callback=callback, disable_pbar=disable_pbar, seed=seed)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/modules/sample_hijack.py\", line 158, in sample_hacked\n",
            "    samples = sampler.sample(model_wrap, sigmas, extra_args, callback_wrap, noise, latent_image, denoise_mask, disable_pbar)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/ldm_patched/modules/samplers.py\", line 557, in sample\n",
            "    samples = self.sampler_function(model_k, noise, sigmas, extra_args=extra_args, callback=k_callback, disable=disable_pbar, **self.extra_options)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/ldm_patched/k_diffusion/sampling.py\", line 701, in sample_dpmpp_2m_sde_gpu\n",
            "    return sample_dpmpp_2m_sde(model, x, sigmas, extra_args=extra_args, callback=callback, disable=disable, eta=eta, s_noise=s_noise, noise_sampler=noise_sampler, solver_type=solver_type)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/ldm_patched/k_diffusion/sampling.py\", line 613, in sample_dpmpp_2m_sde\n",
            "    denoised = model(x, sigmas[i] * s_in, **extra_args)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/modules/patch.py\", line 321, in patched_KSamplerX0Inpaint_forward\n",
            "    out = self.inner_model(x, sigma,\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/ldm_patched/modules/samplers.py\", line 271, in forward\n",
            "    return self.apply_model(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/ldm_patched/modules/samplers.py\", line 268, in apply_model\n",
            "    out = sampling_function(self.inner_model, x, timestep, uncond, cond, cond_scale, model_options=model_options, seed=seed)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/modules/patch.py\", line 237, in patched_sampling_function\n",
            "    positive_x0, negative_x0 = calc_cond_uncond_batch(model, cond, uncond, x, timestep, model_options)\n",
            "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/ldm_patched/modules/samplers.py\", line 222, in calc_cond_uncond_batch\n",
            "    output = model.apply_model(input_x, timestep_, **c).chunk(batch_chunks)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/ldm_patched/modules/model_base.py\", line 85, in apply_model\n",
            "    model_output = self.diffusion_model(xc, t, context=context, control=control, transformer_options=transformer_options, **extra_conds).float()\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/modules/patch.py\", line 437, in patched_unet_forward\n",
            "    h = forward_timestep_embed(module, h, emb, context, transformer_options, output_shape, time_context=time_context, num_video_frames=num_video_frames, image_only_indicator=image_only_indicator)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/ldm_patched/ldm/modules/diffusionmodules/openaimodel.py\", line 43, in forward_timestep_embed\n",
            "    x = layer(x, context, transformer_options)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/ldm_patched/ldm/modules/attention.py\", line 613, in forward\n",
            "    x = block(x, context=context[i], transformer_options=transformer_options)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/ldm_patched/ldm/modules/attention.py\", line 440, in forward\n",
            "    return checkpoint(self._forward, (x, context, transformer_options), self.parameters(), self.checkpoint)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/ldm_patched/ldm/modules/diffusionmodules/util.py\", line 189, in checkpoint\n",
            "    return func(*inputs)\n",
            "           ^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/ldm_patched/ldm/modules/attention.py\", line 550, in _forward\n",
            "    x = self.ff(self.norm3(x))\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/ldm_patched/ldm/modules/attention.py\", line 82, in forward\n",
            "    return self.net(x)\n",
            "           ^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\", line 250, in forward\n",
            "    input = module(input)\n",
            "            ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/ldm_patched/ldm/modules/attention.py\", line 62, in forward\n",
            "    return x * F.gelu(gate)\n",
            "           ~~^~~~~~~~~~~~~~\n",
            "torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 20.12 MiB is free. Process 29332 has 14.72 GiB memory in use. Of the allocated memory 14.16 GiB is allocated by PyTorch, and 427.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Total time: 8.32 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.7 : 0.3\n",
            "[Parameters] Seed = 9164143057042893881\n",
            "[Parameters] CFG = 3\n",
            "[Fooocus] Downloading control models ...\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 60\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.02 seconds\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.11 seconds\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Image processing ...\n",
            "Detected 1 faces\n",
            "Requested to load CLIPVisionModelWithProjection\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.70 seconds\n",
            "Requested to load Resampler\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.40 seconds\n",
            "Requested to load To_KV\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.23 seconds\n",
            "FreeU is enabled!\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (1152, 896)\n",
            "Preparation time: 6.95 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/1 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.74 seconds\n",
            "  0% 0/60 [00:00<?, ?it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Fooocus/modules/async_worker.py\", line 1471, in worker\n",
            "    handler(task)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/modules/async_worker.py\", line 1286, in handler\n",
            "    imgs, img_paths, current_progress = process_task(all_steps, async_task, callback, controlnet_canny_path,\n",
            "                                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/modules/async_worker.py\", line 295, in process_task\n",
            "    imgs = pipeline.process_diffusion(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/modules/default_pipeline.py\", line 379, in process_diffusion\n",
            "    sampled_latent = core.ksampler(\n",
            "                     ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/modules/core.py\", line 310, in ksampler\n",
            "    samples = ldm_patched.modules.sample.sample(model,\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/ldm_patched/modules/sample.py\", line 100, in sample\n",
            "    samples = sampler.sample(noise, positive_copy, negative_copy, cfg=cfg, latent_image=latent_image, start_step=start_step, last_step=last_step, force_full_denoise=force_full_denoise, denoise_mask=noise_mask, sigmas=sigmas, callback=callback, disable_pbar=disable_pbar, seed=seed)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/ldm_patched/modules/samplers.py\", line 712, in sample\n",
            "    return sample(self.model, noise, positive, negative, cfg, self.device, sampler, sigmas, self.model_options, latent_image=latent_image, denoise_mask=denoise_mask, callback=callback, disable_pbar=disable_pbar, seed=seed)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/modules/sample_hijack.py\", line 158, in sample_hacked\n",
            "    samples = sampler.sample(model_wrap, sigmas, extra_args, callback_wrap, noise, latent_image, denoise_mask, disable_pbar)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/ldm_patched/modules/samplers.py\", line 557, in sample\n",
            "    samples = self.sampler_function(model_k, noise, sigmas, extra_args=extra_args, callback=k_callback, disable=disable_pbar, **self.extra_options)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/ldm_patched/k_diffusion/sampling.py\", line 701, in sample_dpmpp_2m_sde_gpu\n",
            "    return sample_dpmpp_2m_sde(model, x, sigmas, extra_args=extra_args, callback=callback, disable=disable, eta=eta, s_noise=s_noise, noise_sampler=noise_sampler, solver_type=solver_type)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/ldm_patched/k_diffusion/sampling.py\", line 613, in sample_dpmpp_2m_sde\n",
            "    denoised = model(x, sigmas[i] * s_in, **extra_args)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/modules/patch.py\", line 321, in patched_KSamplerX0Inpaint_forward\n",
            "    out = self.inner_model(x, sigma,\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/ldm_patched/modules/samplers.py\", line 271, in forward\n",
            "    return self.apply_model(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/ldm_patched/modules/samplers.py\", line 268, in apply_model\n",
            "    out = sampling_function(self.inner_model, x, timestep, uncond, cond, cond_scale, model_options=model_options, seed=seed)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/modules/patch.py\", line 237, in patched_sampling_function\n",
            "    positive_x0, negative_x0 = calc_cond_uncond_batch(model, cond, uncond, x, timestep, model_options)\n",
            "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/ldm_patched/modules/samplers.py\", line 222, in calc_cond_uncond_batch\n",
            "    output = model.apply_model(input_x, timestep_, **c).chunk(batch_chunks)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/ldm_patched/modules/model_base.py\", line 85, in apply_model\n",
            "    model_output = self.diffusion_model(xc, t, context=context, control=control, transformer_options=transformer_options, **extra_conds).float()\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/modules/patch.py\", line 437, in patched_unet_forward\n",
            "    h = forward_timestep_embed(module, h, emb, context, transformer_options, output_shape, time_context=time_context, num_video_frames=num_video_frames, image_only_indicator=image_only_indicator)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/ldm_patched/ldm/modules/diffusionmodules/openaimodel.py\", line 43, in forward_timestep_embed\n",
            "    x = layer(x, context, transformer_options)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/ldm_patched/ldm/modules/attention.py\", line 613, in forward\n",
            "    x = block(x, context=context[i], transformer_options=transformer_options)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/ldm_patched/ldm/modules/attention.py\", line 440, in forward\n",
            "    return checkpoint(self._forward, (x, context, transformer_options), self.parameters(), self.checkpoint)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/ldm_patched/ldm/modules/diffusionmodules/util.py\", line 189, in checkpoint\n",
            "    return func(*inputs)\n",
            "           ^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/ldm_patched/ldm/modules/attention.py\", line 550, in _forward\n",
            "    x = self.ff(self.norm3(x))\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/ldm_patched/ldm/modules/attention.py\", line 82, in forward\n",
            "    return self.net(x)\n",
            "           ^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\", line 250, in forward\n",
            "    input = module(input)\n",
            "            ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/ldm_patched/ldm/modules/attention.py\", line 62, in forward\n",
            "    return x * F.gelu(gate)\n",
            "           ~~^~~~~~~~~~~~~~\n",
            "torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 20.12 MiB is free. Process 29332 has 14.72 GiB memory in use. Of the allocated memory 14.16 GiB is allocated by PyTorch, and 426.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Total time: 8.12 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.7 : 0.3\n",
            "[Parameters] Seed = 1260030211843450329\n",
            "[Parameters] CFG = 3\n",
            "[Fooocus] Downloading control models ...\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 24\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.19 seconds\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.14 seconds\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Image processing ...\n",
            "Detected 1 faces\n",
            "Requested to load CLIPVisionModelWithProjection\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.72 seconds\n",
            "Requested to load Resampler\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.44 seconds\n",
            "Requested to load To_KV\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.24 seconds\n",
            "FreeU is enabled!\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (1152, 896)\n",
            "Preparation time: 7.48 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/1 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.77 seconds\n",
            "100% 60/60 [00:59<00:00,  1.00it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.26 seconds\n",
            "[Fooocus] Saving image 1/1 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-05-07/log.html\n",
            "Generating and saving time: 63.41 seconds\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 63.41 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 70.92 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.95 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.7 : 0.3\n",
            "[Parameters] Seed = 4467006351602432541\n",
            "[Parameters] CFG = 3\n",
            "[Fooocus] Downloading upscale models ...\n",
            "[Inpaint] Parameterized inpaint is disabled.\n",
            "[Fooocus] Downloading control models ...\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 24\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.12 seconds\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Image processing ...\n",
            "Upscaling image with shape (173, 173, 3) ...\n",
            "[Fooocus] VAE Inpaint encoding ...\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.46 seconds\n",
            "[Fooocus] VAE encoding ...\n",
            "Final resolution is (896, 1152), latent is (1024, 1024).\n",
            "Detected 1 faces\n",
            "Requested to load CLIPVisionModelWithProjection\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.54 seconds\n",
            "Requested to load Resampler\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.44 seconds\n",
            "Requested to load To_KV\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.25 seconds\n",
            "FreeU is enabled!\n",
            "[Parameters] Denoising Strength = 0.5\n",
            "[Parameters] Initial Latent shape: torch.Size([1, 4, 128, 128])\n",
            "Preparation time: 10.64 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/1 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 1.2431749105453491\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.77 seconds\n",
            "100% 60/60 [01:03<00:00,  1.06s/it]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.26 seconds\n",
            "[Fooocus] Saving image 1/1 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-05-07/log.html\n",
            "Generating and saving time: 66.96 seconds\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 66.96 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 77.63 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.97 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.7 : 0.3\n",
            "[Parameters] Seed = 2113672475833093204\n",
            "[Parameters] CFG = 3\n",
            "[Fooocus] Downloading control models ...\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 24\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.12 seconds\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Image processing ...\n",
            "Detected 1 faces\n",
            "Requested to load CLIPVisionModelWithProjection\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.86 seconds\n",
            "Requested to load Resampler\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.52 seconds\n",
            "Requested to load To_KV\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.30 seconds\n",
            "FreeU is enabled!\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (1152, 896)\n",
            "Preparation time: 6.53 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/1 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.87 seconds\n",
            "100% 60/60 [01:01<00:00,  1.03s/it]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.25 seconds\n",
            "[Fooocus] Saving image 1/1 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-05-07/log.html\n",
            "Generating and saving time: 65.41 seconds\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 65.41 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 71.96 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.00 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.7 : 0.3\n",
            "[Parameters] Seed = 352991997585146182\n",
            "[Parameters] CFG = 3\n",
            "[Fooocus] Downloading upscale models ...\n",
            "[Inpaint] Parameterized inpaint is disabled.\n",
            "[Fooocus] Downloading control models ...\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 24\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.14 seconds\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Image processing ...\n",
            "Upscaling image with shape (221, 221, 3) ...\n",
            "[Fooocus] VAE Inpaint encoding ...\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.47 seconds\n",
            "[Fooocus] VAE encoding ...\n",
            "Final resolution is (896, 1152), latent is (1024, 1024).\n",
            "Detected 1 faces\n",
            "Requested to load CLIPVisionModelWithProjection\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.55 seconds\n",
            "Requested to load Resampler\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.44 seconds\n",
            "Requested to load To_KV\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.28 seconds\n",
            "FreeU is enabled!\n",
            "[Parameters] Denoising Strength = 0.5\n",
            "[Parameters] Initial Latent shape: torch.Size([1, 4, 128, 128])\n",
            "Preparation time: 9.69 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/1 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 1.2431749105453491\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.84 seconds\n",
            "100% 60/60 [00:59<00:00,  1.00it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.26 seconds\n",
            "[Fooocus] Saving image 1/1 to system ...\n",
            "[Cache] Calculating sha256 for /content/Fooocus/models/checkpoints/realisticStockPhoto_v20.safetensors\n",
            "[Cache] sha256 for /content/Fooocus/models/checkpoints/realisticStockPhoto_v20.safetensors: f99f3dec38\n",
            "[Cache] Calculating sha256 for /content/Fooocus/models/loras/SDXL_FILM_PHOTOGRAPHY_STYLE_V1.safetensors\n",
            "[Cache] sha256 for /content/Fooocus/models/loras/SDXL_FILM_PHOTOGRAPHY_STYLE_V1.safetensors: 9e2a98e1f2\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-05-07/log.html\n",
            "Generating and saving time: 109.83 seconds\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 109.83 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 119.54 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.17 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.7 : 0.3\n",
            "[Parameters] Seed = 1089904323329172313\n",
            "[Parameters] CFG = 3\n",
            "[Fooocus] Downloading control models ...\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 24\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.12 seconds\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Image processing ...\n",
            "Detected 1 faces\n",
            "Requested to load CLIPVisionModelWithProjection\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.74 seconds\n",
            "Requested to load Resampler\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.45 seconds\n",
            "Requested to load To_KV\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.24 seconds\n",
            "FreeU is enabled!\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (1152, 896)\n",
            "Preparation time: 6.16 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/1 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.78 seconds\n",
            "100% 60/60 [00:57<00:00,  1.04it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.26 seconds\n",
            "[Fooocus] Saving image 1/1 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-05-07/log.html\n",
            "Generating and saving time: 61.09 seconds\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 61.09 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 67.27 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.96 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.7 : 0.3\n",
            "[Parameters] Seed = 467441967788212729\n",
            "[Parameters] CFG = 3\n",
            "[Fooocus] Downloading upscale models ...\n",
            "[Inpaint] Parameterized inpaint is disabled.\n",
            "[Fooocus] Downloading control models ...\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 24\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.12 seconds\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Image processing ...\n",
            "Upscaling image with shape (195, 195, 3) ...\n",
            "[Fooocus] VAE Inpaint encoding ...\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.45 seconds\n",
            "[Fooocus] VAE encoding ...\n",
            "Final resolution is (896, 1152), latent is (1024, 1024).\n",
            "Detected 1 faces\n",
            "Requested to load CLIPVisionModelWithProjection\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.54 seconds\n",
            "Requested to load Resampler\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.45 seconds\n",
            "Requested to load To_KV\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.25 seconds\n",
            "FreeU is enabled!\n",
            "[Parameters] Denoising Strength = 0.5\n",
            "[Parameters] Initial Latent shape: torch.Size([1, 4, 128, 128])\n",
            "Preparation time: 9.68 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/1 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 1.2431749105453491\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.87 seconds\n",
            "100% 60/60 [01:02<00:00,  1.03s/it]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.30 seconds\n",
            "[Fooocus] Saving image 1/1 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-05-07/log.html\n",
            "Generating and saving time: 65.77 seconds\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 65.77 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 75.48 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.98 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.7 : 0.3\n",
            "[Parameters] Seed = 4612253582706462410\n",
            "[Parameters] CFG = 3\n",
            "[Fooocus] Downloading upscale models ...\n",
            "[Inpaint] Parameterized inpaint is disabled.\n",
            "[Fooocus] Downloading control models ...\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 24\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.12 seconds\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Image processing ...\n",
            "Upscaling image with shape (259, 259, 3) ...\n",
            "[Fooocus] VAE Inpaint encoding ...\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.55 seconds\n",
            "[Fooocus] VAE encoding ...\n",
            "Final resolution is (896, 1152), latent is (1024, 1024).\n",
            "Detected 1 faces\n",
            "Requested to load CLIPVisionModelWithProjection\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.55 seconds\n",
            "Requested to load Resampler\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.44 seconds\n",
            "Requested to load To_KV\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.26 seconds\n",
            "FreeU is enabled!\n",
            "[Parameters] Denoising Strength = 0.5\n",
            "[Parameters] Initial Latent shape: torch.Size([1, 4, 128, 128])\n",
            "Preparation time: 10.16 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/1 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 1.2431749105453491\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.75 seconds\n",
            "100% 60/60 [01:02<00:00,  1.04s/it]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.24 seconds\n",
            "[Fooocus] Saving image 1/1 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-05-07/log.html\n",
            "Generating and saving time: 65.85 seconds\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 65.85 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 76.03 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.05 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.7 : 0.3\n",
            "[Parameters] Seed = 7440528513066170068\n",
            "[Parameters] CFG = 3\n",
            "[Fooocus] Downloading upscale models ...\n",
            "[Inpaint] Parameterized inpaint is disabled.\n",
            "[Fooocus] Downloading control models ...\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 24\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.13 seconds\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Image processing ...\n",
            "Upscaling image with shape (259, 259, 3) ...\n",
            "[Fooocus] VAE Inpaint encoding ...\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.47 seconds\n",
            "[Fooocus] VAE encoding ...\n",
            "Final resolution is (896, 1152), latent is (1024, 1024).\n",
            "Detected 1 faces\n",
            "Requested to load CLIPVisionModelWithProjection\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.56 seconds\n",
            "Requested to load Resampler\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.44 seconds\n",
            "Requested to load To_KV\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.25 seconds\n",
            "FreeU is enabled!\n",
            "[Parameters] Denoising Strength = 0.5\n",
            "[Parameters] Initial Latent shape: torch.Size([1, 4, 128, 128])\n",
            "Preparation time: 11.06 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/1 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 1.2431749105453491\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.76 seconds\n",
            "100% 60/60 [01:01<00:00,  1.03s/it]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.25 seconds\n",
            "[Fooocus] Saving image 1/1 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-05-07/log.html\n",
            "Generating and saving time: 65.51 seconds\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 65.51 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 76.60 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.96 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.7 : 0.3\n",
            "[Parameters] Seed = 7733544330959004784\n",
            "[Parameters] CFG = 3\n",
            "[Fooocus] Downloading upscale models ...\n",
            "[Inpaint] Parameterized inpaint is disabled.\n",
            "[Fooocus] Downloading control models ...\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 24\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.14 seconds\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Image processing ...\n",
            "Upscaling image with shape (259, 259, 3) ...\n",
            "[Fooocus] VAE Inpaint encoding ...\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.47 seconds\n",
            "[Fooocus] VAE encoding ...\n",
            "Final resolution is (896, 1152), latent is (1024, 1024).\n",
            "Detected 1 faces\n",
            "Requested to load CLIPVisionModelWithProjection\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.53 seconds\n",
            "Requested to load Resampler\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.43 seconds\n",
            "Requested to load To_KV\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.25 seconds\n",
            "FreeU is enabled!\n",
            "[Parameters] Denoising Strength = 0.5\n",
            "[Parameters] Initial Latent shape: torch.Size([1, 4, 128, 128])\n",
            "Preparation time: 10.03 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/1 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 1.2431749105453491\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.75 seconds\n",
            "100% 60/60 [01:04<00:00,  1.08s/it]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.29 seconds\n",
            "[Fooocus] Saving image 1/1 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-05-07/log.html\n",
            "Generating and saving time: 68.34 seconds\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 68.34 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 78.39 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.95 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.7 : 0.3\n",
            "[Parameters] Seed = 405750643862272943\n",
            "[Parameters] CFG = 3\n",
            "[Fooocus] Downloading control models ...\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 24\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.12 seconds\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Image processing ...\n",
            "Detected 1 faces\n",
            "Requested to load CLIPVisionModelWithProjection\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.72 seconds\n",
            "Requested to load Resampler\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.45 seconds\n",
            "Requested to load To_KV\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.24 seconds\n",
            "FreeU is enabled!\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (1152, 896)\n",
            "Preparation time: 5.99 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/1 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.83 seconds\n",
            "100% 60/60 [01:01<00:00,  1.03s/it]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.29 seconds\n",
            "[Fooocus] Saving image 1/1 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-05-07/log.html\n",
            "Generating and saving time: 65.62 seconds\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 65.62 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 71.64 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.94 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.7 : 0.3\n",
            "[Parameters] Seed = 3333469155890594869\n",
            "[Parameters] CFG = 3\n",
            "[Fooocus] Downloading control models ...\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 24\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.12 seconds\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Image processing ...\n",
            "Detected 1 faces\n",
            "Requested to load CLIPVisionModelWithProjection\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.74 seconds\n",
            "Requested to load Resampler\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.50 seconds\n",
            "Requested to load To_KV\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.26 seconds\n",
            "FreeU is enabled!\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (1152, 896)\n",
            "Preparation time: 6.20 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/1 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.84 seconds\n",
            " 72% 43/60 [00:46<00:18,  1.07s/it]\n",
            "User stopped\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 46.85 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 53.06 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.92 seconds\n",
            "Downloading data from 'https://github.com/danielgatis/rembg/releases/download/v0.0.0/silueta.onnx' to file '/content/Fooocus/models/inpaint/silueta.onnx'.\n",
            "100%|██████████████████████████████████████| 44.2M/44.2M [00:00<00:00, 217GB/s]\n",
            "Downloading data from 'https://github.com/danielgatis/rembg/releases/download/v0.0.0/isnet-general-use.onnx' to file '/content/Fooocus/models/inpaint/isnet-general-use.onnx'.\n",
            "100%|████████████████████████████████████████| 179M/179M [00:00<00:00, 772GB/s]\n",
            "Downloading: \"https://huggingface.co/lllyasviel/misc/resolve/main/model_base_caption_capfilt_large.pth\" to /content/Fooocus/models/clip_vision/model_base_caption_capfilt_large.pth\n",
            "\n",
            "100% 855M/855M [00:28<00:00, 31.7MB/s]\n",
            "load checkpoint from /content/Fooocus/models/clip_vision/model_base_caption_capfilt_large.pth\n",
            "Requested to load BLIP_Decoder\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.64 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.7 : 0.3\n",
            "[Parameters] Seed = 609810990222798178\n",
            "[Parameters] CFG = 3\n",
            "[Fooocus] Downloading control models ...\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 24\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "[Fooocus Model Management] Moving model(s) has taken 2.29 seconds\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] [Ultra-realistic DSLR photo of a Billie Eilish-inspired goth female model, medium shot, straight teal shoulder-length hair with full bangs, pale porcelain skin with soft pink undertones, intense blue eyes, thick natural eyebrows, oval face, small refined nose, full matte lips, soft gothic eyeliner and light eyeshadow, [sitting on the bed in the middle of the ass] cinematic depth, natural wet ground reflections, extremely detailed skin and eyes, facial symmetry, sharp focus, ultra-high definition, 4K resolution, perfect lighting balance, photorealistic texture.], elegant, intricate, highly enhanced, very, beautiful, delicate, cute, aesthetic, romantic\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.12 seconds\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Image processing ...\n",
            "Detected 1 faces\n",
            "Requested to load CLIPVisionModelWithProjection\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.89 seconds\n",
            "Requested to load Resampler\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.47 seconds\n",
            "Requested to load To_KV\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.27 seconds\n",
            "FreeU is enabled!\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (1152, 896)\n",
            "Preparation time: 8.98 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/1 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 4.96 seconds\n",
            " 48% 29/60 [00:28<00:30,  1.01it/s]\n",
            "User stopped\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 33.68 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 42.68 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 2.21 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.7 : 0.3\n",
            "[Parameters] Seed = 6551856384544021445\n",
            "[Parameters] CFG = 3\n",
            "[Fooocus] Downloading control models ...\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 24\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] [Ultra-realistic DSLR photo of a Billie Eilish-inspired goth female model, medium shot, straight teal shoulder-length hair with full bangs, pale porcelain skin with soft pink undertones, intense blue eyes, thick natural eyebrows, oval face, small refined nose, full matte lips, soft gothic eyeliner and light eyeshadow, [sitting on the bed in the middle of the ass] cinematic depth, natural wet ground reflections, extremely detailed skin and eyes, facial symmetry, sharp focus, ultra-high definition, 4K resolution, perfect lighting balance, photorealistic texture.], elegant, intricate, highly fried, elite, theatrical, surreal, determined, beautiful, dramatic\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.12 seconds\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Image processing ...\n",
            "Detected 1 faces\n",
            "Requested to load CLIPVisionModelWithProjection\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.73 seconds\n",
            "Requested to load Resampler\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.43 seconds\n",
            "Requested to load To_KV\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.23 seconds\n",
            "FreeU is enabled!\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (1152, 896)\n",
            "Preparation time: 5.93 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/1 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 5.04 seconds\n",
            "100% 60/60 [01:00<00:00,  1.00s/it]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.26 seconds\n",
            "[Fooocus] Saving image 1/1 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-05-07/log.html\n",
            "Generating and saving time: 68.16 seconds\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 68.16 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 74.12 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 2.16 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.7 : 0.3\n",
            "[Parameters] Seed = 836675838740378568\n",
            "[Parameters] CFG = 3\n",
            "[Fooocus] Downloading control models ...\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 24\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] [Ultra-realistic DSLR photo of a female model with a gothic [nude body/hair] inspired by Billie Eilish, medium shot, straight teal shoulder-length hair with full bangs, pale porcelain skin with soft pink undertones, intense blue eyes, thick natural eyebrows, oval face, small refined nose, full matte lips, soft gothic eyeliner and light eyeshadow, [nude body/hair], cinematic depth, natural wet ground reflections, extremely detailed skin and eyes, facial symmetry, sharp focus [nude body/hair], ultra-high definition, 4K resolution, perfect lighting balance, photorealistic texture.], beautiful intricate stunning highly structured gorgeous cute pretty futuristic\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.12 seconds\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Image processing ...\n",
            "Detected 1 faces\n",
            "Requested to load CLIPVisionModelWithProjection\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.77 seconds\n",
            "Requested to load Resampler\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.47 seconds\n",
            "Requested to load To_KV\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.26 seconds\n",
            "FreeU is enabled!\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (1152, 896)\n",
            "Preparation time: 6.50 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/1 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 4.96 seconds\n",
            "100% 60/60 [01:00<00:00,  1.01s/it]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.27 seconds\n",
            "[Fooocus] Saving image 1/1 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-05-07/log.html\n",
            "Generating and saving time: 68.12 seconds\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 68.12 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 74.65 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 2.28 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.7 : 0.3\n",
            "[Parameters] Seed = 810476056080024566\n",
            "[Parameters] CFG = 3\n",
            "[Fooocus] Downloading upscale models ...\n",
            "[Inpaint] Parameterized inpaint is disabled.\n",
            "[Fooocus] Downloading control models ...\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 24\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] [Ultra-realistic DSLR photo of a female model with a gothic [nude body/hair] inspired by Billie Eilish, medium shot, straight teal shoulder-length hair with full bangs, pale porcelain skin with soft pink undertones, intense blue eyes, thick natural eyebrows, oval face, small refined nose, full matte lips, soft gothic eyeliner and light eyeshadow, [nude body/hair], cinematic depth, natural wet ground reflections, extremely detailed skin and eyes, facial symmetry, sharp focus [nude body/hair], ultra-high definition, 4K resolution, perfect lighting balance, photorealistic texture.], elegant, intricate, highly contrasted, stunning\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.13 seconds\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Image processing ...\n",
            "Upscaling image with shape (407, 407, 3) ...\n",
            "[Fooocus] VAE Inpaint encoding ...\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.50 seconds\n",
            "[Fooocus] VAE encoding ...\n",
            "Final resolution is (896, 1152), latent is (1024, 1024).\n",
            "Detected 1 faces\n",
            "Requested to load CLIPVisionModelWithProjection\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.60 seconds\n",
            "Requested to load Resampler\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.47 seconds\n",
            "Requested to load To_KV\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.26 seconds\n",
            "FreeU is enabled!\n",
            "[Parameters] Denoising Strength = 0.5\n",
            "[Parameters] Initial Latent shape: torch.Size([1, 4, 128, 128])\n",
            "Preparation time: 12.20 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/1 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 1.2431749105453491\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 4.93 seconds\n",
            "100% 60/60 [01:00<00:00,  1.01s/it]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.25 seconds\n",
            "[Fooocus] Saving image 1/1 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-05-07/log.html\n",
            "Generating and saving time: 68.60 seconds\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 68.60 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 80.83 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 2.19 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.7 : 0.3\n",
            "[Parameters] Seed = 1051312400397838353\n",
            "[Parameters] CFG = 3\n",
            "[Fooocus] Downloading upscale models ...\n",
            "[Inpaint] Parameterized inpaint is disabled.\n",
            "[Fooocus] Downloading control models ...\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 24\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] [Ultra-realistic DSLR photo of a female model with a gothic [nude body/hair] inspired by Billie Eilish, medium shot, straight teal shoulder-length hair with full bangs, pale porcelain skin with soft pink undertones, intense blue eyes, thick natural eyebrows, oval face, small refined nose, full matte lips, soft gothic eyeliner and light eyeshadow, [nude body/hair], cinematic depth, natural wet ground reflections, extremely detailed skin and eyes, facial symmetry, sharp focus [nude body/hair], ultra-high definition, 4K resolution, perfect lighting balance, photorealistic texture.], beautiful professional stunning elegant, intricate, highly endowed\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.12 seconds\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Image processing ...\n",
            "Upscaling image with shape (407, 407, 3) ...\n",
            "[Fooocus] VAE Inpaint encoding ...\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.50 seconds\n",
            "[Fooocus] VAE encoding ...\n",
            "Final resolution is (896, 1152), latent is (1024, 1024).\n",
            "Detected 1 faces\n",
            "Requested to load CLIPVisionModelWithProjection\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.55 seconds\n",
            "Requested to load Resampler\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.46 seconds\n",
            "Requested to load To_KV\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.25 seconds\n",
            "FreeU is enabled!\n",
            "[Parameters] Denoising Strength = 0.5\n",
            "[Parameters] Initial Latent shape: torch.Size([1, 4, 128, 128])\n",
            "Preparation time: 11.91 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/1 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 1.2431749105453491\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 5.05 seconds\n",
            "100% 60/60 [01:00<00:00,  1.01s/it]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.24 seconds\n",
            "[Fooocus] Saving image 1/1 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-05-07/log.html\n",
            "Generating and saving time: 68.70 seconds\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 68.70 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 80.65 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 2.45 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.7 : 0.3\n",
            "[Parameters] Seed = 3006162781554276874\n",
            "[Parameters] CFG = 3\n",
            "[Fooocus] Downloading upscale models ...\n",
            "[Inpaint] Parameterized inpaint is disabled.\n",
            "[Fooocus] Downloading control models ...\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 24\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] RAW photo, ultra-realistic DSLR photo, full body of a gothic female model inspired by Billie Eilish, lying on a bed in a dark bedroom, body turned towards the camera, soft and mysterious expression, cinematic soft lighting, gentle colors, very beautiful, inspiring, intricate, detailed, innocent, enhanced, romantic, vibrant, symmetry, fine\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.12 seconds\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Image processing ...\n",
            "Upscaling image with shape (407, 407, 3) ...\n",
            "[Fooocus] VAE Inpaint encoding ...\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.51 seconds\n",
            "[Fooocus] VAE encoding ...\n",
            "Final resolution is (896, 1152), latent is (1024, 1024).\n",
            "Detected 1 faces\n",
            "Requested to load CLIPVisionModelWithProjection\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.53 seconds\n",
            "Requested to load Resampler\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.46 seconds\n",
            "Requested to load To_KV\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.25 seconds\n",
            "FreeU is enabled!\n",
            "[Parameters] Denoising Strength = 0.5\n",
            "[Parameters] Initial Latent shape: torch.Size([1, 4, 128, 128])\n",
            "Preparation time: 11.78 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/1 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 1.2431749105453491\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 5.05 seconds\n",
            " 20% 12/60 [00:13<00:54,  1.13s/it]\n",
            "User stopped\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 18.65 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 30.50 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 2.32 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.7 : 0.3\n",
            "[Parameters] Seed = 1248261079141326723\n",
            "[Parameters] CFG = 3\n",
            "[Fooocus] Downloading control models ...\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 24\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] RAW photo, ultra-realistic DSLR photo, full body of a gothic female model inspired by Billie Eilish, lying on a bed in a dark bedroom, body turned towards the camera, soft and mysterious expression, cinematic soft lighting, very detailed, magical, sharp focus, extremely fine detail, intricate, innocent, beautiful, symmetry, highly educated\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.12 seconds\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Image processing ...\n",
            "Detected 1 faces\n",
            "Requested to load CLIPVisionModelWithProjection\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.82 seconds\n",
            "Requested to load Resampler\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.46 seconds\n",
            "Requested to load To_KV\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.25 seconds\n",
            "FreeU is enabled!\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (1152, 896)\n",
            "Preparation time: 6.27 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/1 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 5.13 seconds\n",
            "100% 60/60 [01:00<00:00,  1.01s/it]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.26 seconds\n",
            "[Fooocus] Saving image 1/1 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-05-07/log.html\n",
            "Generating and saving time: 68.37 seconds\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 68.37 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 74.66 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 2.20 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.7 : 0.3\n",
            "[Parameters] Seed = 5838847948428860264\n",
            "[Parameters] CFG = 3\n",
            "[Fooocus] Downloading control models ...\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 24\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] RAW photo, ultra-realistic DSLR photo, full body of a gothic female model inspired by Billie Eilish, lying on a bed in a dark bedroom, body turned towards the camera, soft and mysterious expression, cinematic soft lighting, clear expressive dynamic dramatic atmosphere, detailed, sharp focus, highly intricate, very inspirational, innocent, fine aesthetic, varied\n",
            "[Fooocus] Preparing Fooocus text #2 ...\n",
            "[Prompt Expansion] RAW photo, ultra-realistic DSLR photo, full body of a gothic female model inspired by Billie Eilish, lying on a bed in a dark bedroom, body turned towards the camera, soft and mysterious expression, cinematic soft lighting, clear expressive dynamic dramatic atmosphere, detailed, sharp focus, highly intricate, very inspirational, innocent, fine aesthetic, varied\n",
            "[Fooocus] Preparing Fooocus text #3 ...\n",
            "[Prompt Expansion] RAW photo, ultra-realistic DSLR photo, full body of a gothic female model inspired by Billie Eilish, lying on a bed in a dark bedroom, body turned towards the camera, soft and mysterious expression, cinematic soft lighting, clear expressive dynamic dramatic atmosphere, detailed, sharp focus, highly intricate, very inspirational, innocent, fine aesthetic, varied\n",
            "[Fooocus] Preparing Fooocus text #4 ...\n",
            "[Prompt Expansion] RAW photo, ultra-realistic DSLR photo, full body of a gothic female model inspired by Billie Eilish, lying on a bed in a dark bedroom, body turned towards the camera, soft and mysterious expression, cinematic soft lighting, clear expressive dynamic dramatic atmosphere, detailed, sharp focus, highly intricate, very inspirational, innocent, fine aesthetic, varied\n",
            "[Fooocus] Preparing Fooocus text #5 ...\n",
            "[Prompt Expansion] RAW photo, ultra-realistic DSLR photo, full body of a gothic female model inspired by Billie Eilish, lying on a bed in a dark bedroom, body turned towards the camera, soft and mysterious expression, cinematic soft lighting, clear expressive dynamic dramatic atmosphere, detailed, sharp focus, highly intricate, very inspirational, innocent, fine aesthetic, varied\n",
            "[Fooocus] Preparing Fooocus text #6 ...\n",
            "[Prompt Expansion] RAW photo, ultra-realistic DSLR photo, full body of a gothic female model inspired by Billie Eilish, lying on a bed in a dark bedroom, body turned towards the camera, soft and mysterious expression, cinematic soft lighting, clear expressive dynamic dramatic atmosphere, detailed, sharp focus, highly intricate, very inspirational, innocent, fine aesthetic, varied\n",
            "[Fooocus] Preparing Fooocus text #7 ...\n",
            "[Prompt Expansion] RAW photo, ultra-realistic DSLR photo, full body of a gothic female model inspired by Billie Eilish, lying on a bed in a dark bedroom, body turned towards the camera, soft and mysterious expression, cinematic soft lighting, clear expressive dynamic dramatic atmosphere, detailed, sharp focus, highly intricate, very inspirational, innocent, fine aesthetic, varied\n",
            "[Fooocus] Preparing Fooocus text #8 ...\n",
            "[Prompt Expansion] RAW photo, ultra-realistic DSLR photo, full body of a gothic female model inspired by Billie Eilish, lying on a bed in a dark bedroom, body turned towards the camera, soft and mysterious expression, cinematic soft lighting, clear expressive dynamic dramatic atmosphere, detailed, sharp focus, highly intricate, very inspirational, innocent, fine aesthetic, varied\n",
            "[Fooocus] Preparing Fooocus text #9 ...\n",
            "[Prompt Expansion] RAW photo, ultra-realistic DSLR photo, full body of a gothic female model inspired by Billie Eilish, lying on a bed in a dark bedroom, body turned towards the camera, soft and mysterious expression, cinematic soft lighting, clear expressive dynamic dramatic atmosphere, detailed, sharp focus, highly intricate, very inspirational, innocent, fine aesthetic, varied\n",
            "[Fooocus] Preparing Fooocus text #10 ...\n",
            "[Prompt Expansion] RAW photo, ultra-realistic DSLR photo, full body of a gothic female model inspired by Billie Eilish, lying on a bed in a dark bedroom, body turned towards the camera, soft and mysterious expression, cinematic soft lighting, clear expressive dynamic dramatic atmosphere, detailed, sharp focus, highly intricate, very inspirational, innocent, fine aesthetic, varied\n",
            "[Fooocus] Preparing Fooocus text #11 ...\n",
            "[Prompt Expansion] RAW photo, ultra-realistic DSLR photo, full body of a gothic female model inspired by Billie Eilish, lying on a bed in a dark bedroom, body turned towards the camera, soft and mysterious expression, cinematic soft lighting, clear expressive dynamic dramatic atmosphere, detailed, sharp focus, highly intricate, very inspirational, innocent, fine aesthetic, varied\n",
            "[Fooocus] Preparing Fooocus text #12 ...\n",
            "[Prompt Expansion] RAW photo, ultra-realistic DSLR photo, full body of a gothic female model inspired by Billie Eilish, lying on a bed in a dark bedroom, body turned towards the camera, soft and mysterious expression, cinematic soft lighting, clear expressive dynamic dramatic atmosphere, detailed, sharp focus, highly intricate, very inspirational, innocent, fine aesthetic, varied\n",
            "[Fooocus] Preparing Fooocus text #13 ...\n",
            "[Prompt Expansion] RAW photo, ultra-realistic DSLR photo, full body of a gothic female model inspired by Billie Eilish, lying on a bed in a dark bedroom, body turned towards the camera, soft and mysterious expression, cinematic soft lighting, clear expressive dynamic dramatic atmosphere, detailed, sharp focus, highly intricate, very inspirational, innocent, fine aesthetic, varied\n",
            "[Fooocus] Preparing Fooocus text #14 ...\n",
            "[Prompt Expansion] RAW photo, ultra-realistic DSLR photo, full body of a gothic female model inspired by Billie Eilish, lying on a bed in a dark bedroom, body turned towards the camera, soft and mysterious expression, cinematic soft lighting, clear expressive dynamic dramatic atmosphere, detailed, sharp focus, highly intricate, very inspirational, innocent, fine aesthetic, varied\n",
            "[Fooocus] Preparing Fooocus text #15 ...\n",
            "[Prompt Expansion] RAW photo, ultra-realistic DSLR photo, full body of a gothic female model inspired by Billie Eilish, lying on a bed in a dark bedroom, body turned towards the camera, soft and mysterious expression, cinematic soft lighting, clear expressive dynamic dramatic atmosphere, detailed, sharp focus, highly intricate, very inspirational, innocent, fine aesthetic, varied\n",
            "[Fooocus] Preparing Fooocus text #16 ...\n",
            "[Prompt Expansion] RAW photo, ultra-realistic DSLR photo, full body of a gothic female model inspired by Billie Eilish, lying on a bed in a dark bedroom, body turned towards the camera, soft and mysterious expression, cinematic soft lighting, clear expressive dynamic dramatic atmosphere, detailed, sharp focus, highly intricate, very inspirational, innocent, fine aesthetic, varied\n",
            "[Fooocus] Preparing Fooocus text #17 ...\n",
            "[Prompt Expansion] RAW photo, ultra-realistic DSLR photo, full body of a gothic female model inspired by Billie Eilish, lying on a bed in a dark bedroom, body turned towards the camera, soft and mysterious expression, cinematic soft lighting, clear expressive dynamic dramatic atmosphere, detailed, sharp focus, highly intricate, very inspirational, innocent, fine aesthetic, varied\n",
            "[Fooocus] Preparing Fooocus text #18 ...\n",
            "[Prompt Expansion] RAW photo, ultra-realistic DSLR photo, full body of a gothic female model inspired by Billie Eilish, lying on a bed in a dark bedroom, body turned towards the camera, soft and mysterious expression, cinematic soft lighting, clear expressive dynamic dramatic atmosphere, detailed, sharp focus, highly intricate, very inspirational, innocent, fine aesthetic, varied\n",
            "[Fooocus] Preparing Fooocus text #19 ...\n",
            "[Prompt Expansion] RAW photo, ultra-realistic DSLR photo, full body of a gothic female model inspired by Billie Eilish, lying on a bed in a dark bedroom, body turned towards the camera, soft and mysterious expression, cinematic soft lighting, clear expressive dynamic dramatic atmosphere, detailed, sharp focus, highly intricate, very inspirational, innocent, fine aesthetic, varied\n",
            "[Fooocus] Preparing Fooocus text #20 ...\n",
            "[Prompt Expansion] RAW photo, ultra-realistic DSLR photo, full body of a gothic female model inspired by Billie Eilish, lying on a bed in a dark bedroom, body turned towards the camera, soft and mysterious expression, cinematic soft lighting, clear expressive dynamic dramatic atmosphere, detailed, sharp focus, highly intricate, very inspirational, innocent, fine aesthetic, varied\n",
            "[Fooocus] Preparing Fooocus text #21 ...\n",
            "[Prompt Expansion] RAW photo, ultra-realistic DSLR photo, full body of a gothic female model inspired by Billie Eilish, lying on a bed in a dark bedroom, body turned towards the camera, soft and mysterious expression, cinematic soft lighting, clear expressive dynamic dramatic atmosphere, detailed, sharp focus, highly intricate, very inspirational, innocent, fine aesthetic, varied\n",
            "[Fooocus] Preparing Fooocus text #22 ...\n",
            "[Prompt Expansion] RAW photo, ultra-realistic DSLR photo, full body of a gothic female model inspired by Billie Eilish, lying on a bed in a dark bedroom, body turned towards the camera, soft and mysterious expression, cinematic soft lighting, clear expressive dynamic dramatic atmosphere, detailed, sharp focus, highly intricate, very inspirational, innocent, fine aesthetic, varied\n",
            "[Fooocus] Preparing Fooocus text #23 ...\n",
            "[Prompt Expansion] RAW photo, ultra-realistic DSLR photo, full body of a gothic female model inspired by Billie Eilish, lying on a bed in a dark bedroom, body turned towards the camera, soft and mysterious expression, cinematic soft lighting, clear expressive dynamic dramatic atmosphere, detailed, sharp focus, highly intricate, very inspirational, innocent, fine aesthetic, varied\n",
            "[Fooocus] Preparing Fooocus text #24 ...\n",
            "[Prompt Expansion] RAW photo, ultra-realistic DSLR photo, full body of a gothic female model inspired by Billie Eilish, lying on a bed in a dark bedroom, body turned towards the camera, soft and mysterious expression, cinematic soft lighting, clear expressive dynamic dramatic atmosphere, detailed, sharp focus, highly intricate, very inspirational, innocent, fine aesthetic, varied\n",
            "[Fooocus] Preparing Fooocus text #25 ...\n",
            "[Prompt Expansion] RAW photo, ultra-realistic DSLR photo, full body of a gothic female model inspired by Billie Eilish, lying on a bed in a dark bedroom, body turned towards the camera, soft and mysterious expression, cinematic soft lighting, clear expressive dynamic dramatic atmosphere, detailed, sharp focus, highly intricate, very inspirational, innocent, fine aesthetic, varied\n",
            "[Fooocus] Preparing Fooocus text #26 ...\n",
            "[Prompt Expansion] RAW photo, ultra-realistic DSLR photo, full body of a gothic female model inspired by Billie Eilish, lying on a bed in a dark bedroom, body turned towards the camera, soft and mysterious expression, cinematic soft lighting, clear expressive dynamic dramatic atmosphere, detailed, sharp focus, highly intricate, very inspirational, innocent, fine aesthetic, varied\n",
            "[Fooocus] Preparing Fooocus text #27 ...\n",
            "[Prompt Expansion] RAW photo, ultra-realistic DSLR photo, full body of a gothic female model inspired by Billie Eilish, lying on a bed in a dark bedroom, body turned towards the camera, soft and mysterious expression, cinematic soft lighting, clear expressive dynamic dramatic atmosphere, detailed, sharp focus, highly intricate, very inspirational, innocent, fine aesthetic, varied\n",
            "[Fooocus] Preparing Fooocus text #28 ...\n",
            "[Prompt Expansion] RAW photo, ultra-realistic DSLR photo, full body of a gothic female model inspired by Billie Eilish, lying on a bed in a dark bedroom, body turned towards the camera, soft and mysterious expression, cinematic soft lighting, clear expressive dynamic dramatic atmosphere, detailed, sharp focus, highly intricate, very inspirational, innocent, fine aesthetic, varied\n",
            "[Fooocus] Preparing Fooocus text #29 ...\n",
            "[Prompt Expansion] RAW photo, ultra-realistic DSLR photo, full body of a gothic female model inspired by Billie Eilish, lying on a bed in a dark bedroom, body turned towards the camera, soft and mysterious expression, cinematic soft lighting, clear expressive dynamic dramatic atmosphere, detailed, sharp focus, highly intricate, very inspirational, innocent, fine aesthetic, varied\n",
            "[Fooocus] Preparing Fooocus text #30 ...\n",
            "[Prompt Expansion] RAW photo, ultra-realistic DSLR photo, full body of a gothic female model inspired by Billie Eilish, lying on a bed in a dark bedroom, body turned towards the camera, soft and mysterious expression, cinematic soft lighting, clear expressive dynamic dramatic atmosphere, detailed, sharp focus, highly intricate, very inspirational, innocent, fine aesthetic, varied\n",
            "[Fooocus] Preparing Fooocus text #31 ...\n",
            "[Prompt Expansion] RAW photo, ultra-realistic DSLR photo, full body of a gothic female model inspired by Billie Eilish, lying on a bed in a dark bedroom, body turned towards the camera, soft and mysterious expression, cinematic soft lighting, clear expressive dynamic dramatic atmosphere, detailed, sharp focus, highly intricate, very inspirational, innocent, fine aesthetic, varied\n",
            "[Fooocus] Preparing Fooocus text #32 ...\n",
            "[Prompt Expansion] RAW photo, ultra-realistic DSLR photo, full body of a gothic female model inspired by Billie Eilish, lying on a bed in a dark bedroom, body turned towards the camera, soft and mysterious expression, cinematic soft lighting, clear expressive dynamic dramatic atmosphere, detailed, sharp focus, highly intricate, very inspirational, innocent, fine aesthetic, varied\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.12 seconds\n",
            "[Fooocus] Encoding positive #2 ...\n",
            "[Fooocus] Encoding positive #3 ...\n",
            "[Fooocus] Encoding positive #4 ...\n",
            "[Fooocus] Encoding positive #5 ...\n",
            "[Fooocus] Encoding positive #6 ...\n",
            "[Fooocus] Encoding positive #7 ...\n",
            "[Fooocus] Encoding positive #8 ...\n",
            "[Fooocus] Encoding positive #9 ...\n",
            "[Fooocus] Encoding positive #10 ...\n",
            "[Fooocus] Encoding positive #11 ...\n",
            "[Fooocus] Encoding positive #12 ...\n",
            "[Fooocus] Encoding positive #13 ...\n",
            "[Fooocus] Encoding positive #14 ...\n",
            "[Fooocus] Encoding positive #15 ...\n",
            "[Fooocus] Encoding positive #16 ...\n",
            "[Fooocus] Encoding positive #17 ...\n",
            "[Fooocus] Encoding positive #18 ...\n",
            "[Fooocus] Encoding positive #19 ...\n",
            "[Fooocus] Encoding positive #20 ...\n",
            "[Fooocus] Encoding positive #21 ...\n",
            "[Fooocus] Encoding positive #22 ...\n",
            "[Fooocus] Encoding positive #23 ...\n",
            "[Fooocus] Encoding positive #24 ...\n",
            "[Fooocus] Encoding positive #25 ...\n",
            "[Fooocus] Encoding positive #26 ...\n",
            "[Fooocus] Encoding positive #27 ...\n",
            "[Fooocus] Encoding positive #28 ...\n",
            "[Fooocus] Encoding positive #29 ...\n",
            "[Fooocus] Encoding positive #30 ...\n",
            "[Fooocus] Encoding positive #31 ...\n",
            "[Fooocus] Encoding positive #32 ...\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Encoding negative #2 ...\n",
            "[Fooocus] Encoding negative #3 ...\n",
            "[Fooocus] Encoding negative #4 ...\n",
            "[Fooocus] Encoding negative #5 ...\n",
            "[Fooocus] Encoding negative #6 ...\n",
            "[Fooocus] Encoding negative #7 ...\n",
            "[Fooocus] Encoding negative #8 ...\n",
            "[Fooocus] Encoding negative #9 ...\n",
            "[Fooocus] Encoding negative #10 ...\n",
            "[Fooocus] Encoding negative #11 ...\n",
            "[Fooocus] Encoding negative #12 ...\n",
            "[Fooocus] Encoding negative #13 ...\n",
            "[Fooocus] Encoding negative #14 ...\n",
            "[Fooocus] Encoding negative #15 ...\n",
            "[Fooocus] Encoding negative #16 ...\n",
            "[Fooocus] Encoding negative #17 ...\n",
            "[Fooocus] Encoding negative #18 ...\n",
            "[Fooocus] Encoding negative #19 ...\n",
            "[Fooocus] Encoding negative #20 ...\n",
            "[Fooocus] Encoding negative #21 ...\n",
            "[Fooocus] Encoding negative #22 ...\n",
            "[Fooocus] Encoding negative #23 ...\n",
            "[Fooocus] Encoding negative #24 ...\n",
            "[Fooocus] Encoding negative #25 ...\n",
            "[Fooocus] Encoding negative #26 ...\n",
            "[Fooocus] Encoding negative #27 ...\n",
            "[Fooocus] Encoding negative #28 ...\n",
            "[Fooocus] Encoding negative #29 ...\n",
            "[Fooocus] Encoding negative #30 ...\n",
            "[Fooocus] Encoding negative #31 ...\n",
            "[Fooocus] Encoding negative #32 ...\n",
            "[Fooocus] Image processing ...\n",
            "Detected 1 faces\n",
            "Requested to load CLIPVisionModelWithProjection\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.76 seconds\n",
            "Requested to load Resampler\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.45 seconds\n",
            "Requested to load To_KV\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.25 seconds\n",
            "FreeU is enabled!\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (1152, 896)\n",
            "Preparation time: 14.52 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/32 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 5.26 seconds\n",
            "100% 60/60 [01:00<00:00,  1.01s/it]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.25 seconds\n",
            "[Fooocus] Saving image 1/32 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-05-07/log.html\n",
            "Generating and saving time: 68.60 seconds\n",
            "[Fooocus] Preparing task 2/32 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 5.07 seconds\n",
            " 87% 52/60 [00:52<00:08,  1.01s/it]\n",
            "User stopped\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 125.99 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 140.57 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 2.23 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.7 : 0.3\n",
            "[Parameters] Seed = 2804548569156201182\n",
            "[Parameters] CFG = 3\n",
            "[Fooocus] Downloading control models ...\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 24\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] RAW photo, ultra-realistic DSLR photo, full body of a gothic female model inspired by Billie Eilish, standing in an empty alleyway at night, casual pose with hands in pockets, confident expression, cinematic soft lighting, beautiful detailed intricate stunning highly detail, focus, fair quality, advanced composition, innocent, complete, symmetry, fine classic\n",
            "[Fooocus] Preparing Fooocus text #2 ...\n",
            "[Prompt Expansion] RAW photo, ultra-realistic DSLR photo, full body of a gothic female model inspired by Billie Eilish, standing in an empty alleyway at night, casual pose with hands in pockets, confident expression, cinematic soft lighting, beautiful detailed intricate stunning highly detail, focus, fair quality, advanced composition, innocent, complete, symmetry, fine classic\n",
            "[Fooocus] Preparing Fooocus text #3 ...\n",
            "[Prompt Expansion] RAW photo, ultra-realistic DSLR photo, full body of a gothic female model inspired by Billie Eilish, standing in an empty alleyway at night, casual pose with hands in pockets, confident expression, cinematic soft lighting, beautiful detailed intricate stunning highly detail, focus, fair quality, advanced composition, innocent, complete, symmetry, fine classic\n",
            "[Fooocus] Preparing Fooocus text #4 ...\n",
            "[Prompt Expansion] RAW photo, ultra-realistic DSLR photo, full body of a gothic female model inspired by Billie Eilish, standing in an empty alleyway at night, casual pose with hands in pockets, confident expression, cinematic soft lighting, beautiful detailed intricate stunning highly detail, focus, fair quality, advanced composition, innocent, complete, symmetry, fine classic\n",
            "[Fooocus] Preparing Fooocus text #5 ...\n",
            "[Prompt Expansion] RAW photo, ultra-realistic DSLR photo, full body of a gothic female model inspired by Billie Eilish, standing in an empty alleyway at night, casual pose with hands in pockets, confident expression, cinematic soft lighting, beautiful detailed intricate stunning highly detail, focus, fair quality, advanced composition, innocent, complete, symmetry, fine classic\n",
            "[Fooocus] Preparing Fooocus text #6 ...\n",
            "[Prompt Expansion] RAW photo, ultra-realistic DSLR photo, full body of a gothic female model inspired by Billie Eilish, standing in an empty alleyway at night, casual pose with hands in pockets, confident expression, cinematic soft lighting, beautiful detailed intricate stunning highly detail, focus, fair quality, advanced composition, innocent, complete, symmetry, fine classic\n",
            "[Fooocus] Preparing Fooocus text #7 ...\n",
            "[Prompt Expansion] RAW photo, ultra-realistic DSLR photo, full body of a gothic female model inspired by Billie Eilish, standing in an empty alleyway at night, casual pose with hands in pockets, confident expression, cinematic soft lighting, beautiful detailed intricate stunning highly detail, focus, fair quality, advanced composition, innocent, complete, symmetry, fine classic\n",
            "[Fooocus] Preparing Fooocus text #8 ...\n",
            "[Prompt Expansion] RAW photo, ultra-realistic DSLR photo, full body of a gothic female model inspired by Billie Eilish, standing in an empty alleyway at night, casual pose with hands in pockets, confident expression, cinematic soft lighting, beautiful detailed intricate stunning highly detail, focus, fair quality, advanced composition, innocent, complete, symmetry, fine classic\n",
            "[Fooocus] Preparing Fooocus text #9 ...\n",
            "[Prompt Expansion] RAW photo, ultra-realistic DSLR photo, full body of a gothic female model inspired by Billie Eilish, standing in an empty alleyway at night, casual pose with hands in pockets, confident expression, cinematic soft lighting, beautiful detailed intricate stunning highly detail, focus, fair quality, advanced composition, innocent, complete, symmetry, fine classic\n",
            "[Fooocus] Preparing Fooocus text #10 ...\n",
            "[Prompt Expansion] RAW photo, ultra-realistic DSLR photo, full body of a gothic female model inspired by Billie Eilish, standing in an empty alleyway at night, casual pose with hands in pockets, confident expression, cinematic soft lighting, beautiful detailed intricate stunning highly detail, focus, fair quality, advanced composition, innocent, complete, symmetry, fine classic\n",
            "[Fooocus] Preparing Fooocus text #11 ...\n",
            "[Prompt Expansion] RAW photo, ultra-realistic DSLR photo, full body of a gothic female model inspired by Billie Eilish, standing in an empty alleyway at night, casual pose with hands in pockets, confident expression, cinematic soft lighting, beautiful detailed intricate stunning highly detail, focus, fair quality, advanced composition, innocent, complete, symmetry, fine classic\n",
            "[Fooocus] Preparing Fooocus text #12 ...\n",
            "[Prompt Expansion] RAW photo, ultra-realistic DSLR photo, full body of a gothic female model inspired by Billie Eilish, standing in an empty alleyway at night, casual pose with hands in pockets, confident expression, cinematic soft lighting, beautiful detailed intricate stunning highly detail, focus, fair quality, advanced composition, innocent, complete, symmetry, fine classic\n",
            "[Fooocus] Preparing Fooocus text #13 ...\n",
            "[Prompt Expansion] RAW photo, ultra-realistic DSLR photo, full body of a gothic female model inspired by Billie Eilish, standing in an empty alleyway at night, casual pose with hands in pockets, confident expression, cinematic soft lighting, beautiful detailed intricate stunning highly detail, focus, fair quality, advanced composition, innocent, complete, symmetry, fine classic\n",
            "[Fooocus] Preparing Fooocus text #14 ...\n",
            "[Prompt Expansion] RAW photo, ultra-realistic DSLR photo, full body of a gothic female model inspired by Billie Eilish, standing in an empty alleyway at night, casual pose with hands in pockets, confident expression, cinematic soft lighting, beautiful detailed intricate stunning highly detail, focus, fair quality, advanced composition, innocent, complete, symmetry, fine classic\n",
            "[Fooocus] Preparing Fooocus text #15 ...\n",
            "[Prompt Expansion] RAW photo, ultra-realistic DSLR photo, full body of a gothic female model inspired by Billie Eilish, standing in an empty alleyway at night, casual pose with hands in pockets, confident expression, cinematic soft lighting, beautiful detailed intricate stunning highly detail, focus, fair quality, advanced composition, innocent, complete, symmetry, fine classic\n",
            "[Fooocus] Preparing Fooocus text #16 ...\n",
            "[Prompt Expansion] RAW photo, ultra-realistic DSLR photo, full body of a gothic female model inspired by Billie Eilish, standing in an empty alleyway at night, casual pose with hands in pockets, confident expression, cinematic soft lighting, beautiful detailed intricate stunning highly detail, focus, fair quality, advanced composition, innocent, complete, symmetry, fine classic\n",
            "[Fooocus] Preparing Fooocus text #17 ...\n",
            "[Prompt Expansion] RAW photo, ultra-realistic DSLR photo, full body of a gothic female model inspired by Billie Eilish, standing in an empty alleyway at night, casual pose with hands in pockets, confident expression, cinematic soft lighting, beautiful detailed intricate stunning highly detail, focus, fair quality, advanced composition, innocent, complete, symmetry, fine classic\n",
            "[Fooocus] Preparing Fooocus text #18 ...\n",
            "[Prompt Expansion] RAW photo, ultra-realistic DSLR photo, full body of a gothic female model inspired by Billie Eilish, standing in an empty alleyway at night, casual pose with hands in pockets, confident expression, cinematic soft lighting, beautiful detailed intricate stunning highly detail, focus, fair quality, advanced composition, innocent, complete, symmetry, fine classic\n",
            "[Fooocus] Preparing Fooocus text #19 ...\n",
            "[Prompt Expansion] RAW photo, ultra-realistic DSLR photo, full body of a gothic female model inspired by Billie Eilish, standing in an empty alleyway at night, casual pose with hands in pockets, confident expression, cinematic soft lighting, beautiful detailed intricate stunning highly detail, focus, fair quality, advanced composition, innocent, complete, symmetry, fine classic\n",
            "[Fooocus] Preparing Fooocus text #20 ...\n",
            "[Prompt Expansion] RAW photo, ultra-realistic DSLR photo, full body of a gothic female model inspired by Billie Eilish, standing in an empty alleyway at night, casual pose with hands in pockets, confident expression, cinematic soft lighting, beautiful detailed intricate stunning highly detail, focus, fair quality, advanced composition, innocent, complete, symmetry, fine classic\n",
            "[Fooocus] Preparing Fooocus text #21 ...\n",
            "[Prompt Expansion] RAW photo, ultra-realistic DSLR photo, full body of a gothic female model inspired by Billie Eilish, standing in an empty alleyway at night, casual pose with hands in pockets, confident expression, cinematic soft lighting, beautiful detailed intricate stunning highly detail, focus, fair quality, advanced composition, innocent, complete, symmetry, fine classic\n",
            "[Fooocus] Preparing Fooocus text #22 ...\n",
            "[Prompt Expansion] RAW photo, ultra-realistic DSLR photo, full body of a gothic female model inspired by Billie Eilish, standing in an empty alleyway at night, casual pose with hands in pockets, confident expression, cinematic soft lighting, beautiful detailed intricate stunning highly detail, focus, fair quality, advanced composition, innocent, complete, symmetry, fine classic\n",
            "[Fooocus] Preparing Fooocus text #23 ...\n",
            "[Prompt Expansion] RAW photo, ultra-realistic DSLR photo, full body of a gothic female model inspired by Billie Eilish, standing in an empty alleyway at night, casual pose with hands in pockets, confident expression, cinematic soft lighting, beautiful detailed intricate stunning highly detail, focus, fair quality, advanced composition, innocent, complete, symmetry, fine classic\n",
            "[Fooocus] Preparing Fooocus text #24 ...\n",
            "[Prompt Expansion] RAW photo, ultra-realistic DSLR photo, full body of a gothic female model inspired by Billie Eilish, standing in an empty alleyway at night, casual pose with hands in pockets, confident expression, cinematic soft lighting, beautiful detailed intricate stunning highly detail, focus, fair quality, advanced composition, innocent, complete, symmetry, fine classic\n",
            "[Fooocus] Preparing Fooocus text #25 ...\n",
            "[Prompt Expansion] RAW photo, ultra-realistic DSLR photo, full body of a gothic female model inspired by Billie Eilish, standing in an empty alleyway at night, casual pose with hands in pockets, confident expression, cinematic soft lighting, beautiful detailed intricate stunning highly detail, focus, fair quality, advanced composition, innocent, complete, symmetry, fine classic\n",
            "[Fooocus] Preparing Fooocus text #26 ...\n",
            "[Prompt Expansion] RAW photo, ultra-realistic DSLR photo, full body of a gothic female model inspired by Billie Eilish, standing in an empty alleyway at night, casual pose with hands in pockets, confident expression, cinematic soft lighting, beautiful detailed intricate stunning highly detail, focus, fair quality, advanced composition, innocent, complete, symmetry, fine classic\n",
            "[Fooocus] Preparing Fooocus text #27 ...\n",
            "[Prompt Expansion] RAW photo, ultra-realistic DSLR photo, full body of a gothic female model inspired by Billie Eilish, standing in an empty alleyway at night, casual pose with hands in pockets, confident expression, cinematic soft lighting, beautiful detailed intricate stunning highly detail, focus, fair quality, advanced composition, innocent, complete, symmetry, fine classic\n",
            "[Fooocus] Preparing Fooocus text #28 ...\n",
            "[Prompt Expansion] RAW photo, ultra-realistic DSLR photo, full body of a gothic female model inspired by Billie Eilish, standing in an empty alleyway at night, casual pose with hands in pockets, confident expression, cinematic soft lighting, beautiful detailed intricate stunning highly detail, focus, fair quality, advanced composition, innocent, complete, symmetry, fine classic\n",
            "[Fooocus] Preparing Fooocus text #29 ...\n",
            "[Prompt Expansion] RAW photo, ultra-realistic DSLR photo, full body of a gothic female model inspired by Billie Eilish, standing in an empty alleyway at night, casual pose with hands in pockets, confident expression, cinematic soft lighting, beautiful detailed intricate stunning highly detail, focus, fair quality, advanced composition, innocent, complete, symmetry, fine classic\n",
            "[Fooocus] Preparing Fooocus text #30 ...\n",
            "[Prompt Expansion] RAW photo, ultra-realistic DSLR photo, full body of a gothic female model inspired by Billie Eilish, standing in an empty alleyway at night, casual pose with hands in pockets, confident expression, cinematic soft lighting, beautiful detailed intricate stunning highly detail, focus, fair quality, advanced composition, innocent, complete, symmetry, fine classic\n",
            "[Fooocus] Preparing Fooocus text #31 ...\n",
            "[Prompt Expansion] RAW photo, ultra-realistic DSLR photo, full body of a gothic female model inspired by Billie Eilish, standing in an empty alleyway at night, casual pose with hands in pockets, confident expression, cinematic soft lighting, beautiful detailed intricate stunning highly detail, focus, fair quality, advanced composition, innocent, complete, symmetry, fine classic\n",
            "[Fooocus] Preparing Fooocus text #32 ...\n",
            "[Prompt Expansion] RAW photo, ultra-realistic DSLR photo, full body of a gothic female model inspired by Billie Eilish, standing in an empty alleyway at night, casual pose with hands in pockets, confident expression, cinematic soft lighting, beautiful detailed intricate stunning highly detail, focus, fair quality, advanced composition, innocent, complete, symmetry, fine classic\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.13 seconds\n",
            "[Fooocus] Encoding positive #2 ...\n",
            "[Fooocus] Encoding positive #3 ...\n",
            "[Fooocus] Encoding positive #4 ...\n",
            "[Fooocus] Encoding positive #5 ...\n",
            "[Fooocus] Encoding positive #6 ...\n",
            "[Fooocus] Encoding positive #7 ...\n",
            "[Fooocus] Encoding positive #8 ...\n",
            "[Fooocus] Encoding positive #9 ...\n",
            "[Fooocus] Encoding positive #10 ...\n",
            "[Fooocus] Encoding positive #11 ...\n",
            "[Fooocus] Encoding positive #12 ...\n",
            "[Fooocus] Encoding positive #13 ...\n",
            "[Fooocus] Encoding positive #14 ...\n",
            "[Fooocus] Encoding positive #15 ...\n",
            "[Fooocus] Encoding positive #16 ...\n",
            "[Fooocus] Encoding positive #17 ...\n",
            "[Fooocus] Encoding positive #18 ...\n",
            "[Fooocus] Encoding positive #19 ...\n",
            "[Fooocus] Encoding positive #20 ...\n",
            "[Fooocus] Encoding positive #21 ...\n",
            "[Fooocus] Encoding positive #22 ...\n",
            "[Fooocus] Encoding positive #23 ...\n",
            "[Fooocus] Encoding positive #24 ...\n",
            "[Fooocus] Encoding positive #25 ...\n",
            "[Fooocus] Encoding positive #26 ...\n",
            "[Fooocus] Encoding positive #27 ...\n",
            "[Fooocus] Encoding positive #28 ...\n",
            "[Fooocus] Encoding positive #29 ...\n",
            "[Fooocus] Encoding positive #30 ...\n",
            "[Fooocus] Encoding positive #31 ...\n",
            "[Fooocus] Encoding positive #32 ...\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Encoding negative #2 ...\n",
            "[Fooocus] Encoding negative #3 ...\n",
            "[Fooocus] Encoding negative #4 ...\n",
            "[Fooocus] Encoding negative #5 ...\n",
            "[Fooocus] Encoding negative #6 ...\n",
            "[Fooocus] Encoding negative #7 ...\n",
            "[Fooocus] Encoding negative #8 ...\n",
            "[Fooocus] Encoding negative #9 ...\n",
            "[Fooocus] Encoding negative #10 ...\n",
            "[Fooocus] Encoding negative #11 ...\n",
            "[Fooocus] Encoding negative #12 ...\n",
            "[Fooocus] Encoding negative #13 ...\n",
            "[Fooocus] Encoding negative #14 ...\n",
            "[Fooocus] Encoding negative #15 ...\n",
            "[Fooocus] Encoding negative #16 ...\n",
            "[Fooocus] Encoding negative #17 ...\n",
            "[Fooocus] Encoding negative #18 ...\n",
            "[Fooocus] Encoding negative #19 ...\n",
            "[Fooocus] Encoding negative #20 ...\n",
            "[Fooocus] Encoding negative #21 ...\n",
            "[Fooocus] Encoding negative #22 ...\n",
            "[Fooocus] Encoding negative #23 ...\n",
            "[Fooocus] Encoding negative #24 ...\n",
            "[Fooocus] Encoding negative #25 ...\n",
            "[Fooocus] Encoding negative #26 ...\n",
            "[Fooocus] Encoding negative #27 ...\n",
            "[Fooocus] Encoding negative #28 ...\n",
            "[Fooocus] Encoding negative #29 ...\n",
            "[Fooocus] Encoding negative #30 ...\n",
            "[Fooocus] Encoding negative #31 ...\n",
            "[Fooocus] Encoding negative #32 ...\n",
            "[Fooocus] Image processing ...\n",
            "Detected 1 faces\n",
            "Requested to load CLIPVisionModelWithProjection\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.75 seconds\n",
            "Requested to load Resampler\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.46 seconds\n",
            "Requested to load To_KV\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.25 seconds\n",
            "FreeU is enabled!\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (1152, 896)\n",
            "Preparation time: 15.53 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/32 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 4.97 seconds\n",
            "100% 60/60 [01:00<00:00,  1.01s/it]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.27 seconds\n",
            "[Fooocus] Saving image 1/32 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-05-07/log.html\n",
            "Generating and saving time: 68.34 seconds\n",
            "[Fooocus] Preparing task 2/32 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 5.02 seconds\n",
            " 77% 46/60 [00:46<00:14,  1.01s/it]\n",
            "User stopped\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 119.85 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 135.39 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 2.26 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.7 : 0.3\n",
            "[Parameters] Seed = 5625566053758430432\n",
            "[Parameters] CFG = 3\n",
            "[Fooocus] Downloading upscale models ...\n",
            "[Inpaint] Parameterized inpaint is disabled.\n",
            "[Fooocus] Downloading control models ...\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 24\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] highly detailed face, bright colors, sunny, friendly, glowing, vivid, beautiful, surreal, pretty, aesthetic, dramatic, intricate, highly detail, professional, cheerful, elegant, best, colorful, light, saturated, amazing, flowing, magic, strong, romantic, complex, artistic, color, atmosphere, iconic, fine, very inspirational, perfect, epic, cinematic\n",
            "[Fooocus] Preparing Fooocus text #2 ...\n",
            "[Prompt Expansion] highly detailed face, bright colors, sunny, friendly, glowing, vivid, beautiful, surreal, pretty, aesthetic, dramatic, intricate, highly detail, professional, cheerful, elegant, best, colorful, light, saturated, amazing, flowing, magic, strong, romantic, complex, artistic, color, atmosphere, iconic, fine, very inspirational, perfect, epic, cinematic\n",
            "[Fooocus] Preparing Fooocus text #3 ...\n",
            "[Prompt Expansion] highly detailed face, bright colors, sunny, friendly, glowing, vivid, beautiful, surreal, pretty, aesthetic, dramatic, intricate, highly detail, professional, cheerful, elegant, best, colorful, light, saturated, amazing, flowing, magic, strong, romantic, complex, artistic, color, atmosphere, iconic, fine, very inspirational, perfect, epic, cinematic\n",
            "[Fooocus] Preparing Fooocus text #4 ...\n",
            "[Prompt Expansion] highly detailed face, bright colors, sunny, friendly, glowing, vivid, beautiful, surreal, pretty, aesthetic, dramatic, intricate, highly detail, professional, cheerful, elegant, best, colorful, light, saturated, amazing, flowing, magic, strong, romantic, complex, artistic, color, atmosphere, iconic, fine, very inspirational, perfect, epic, cinematic\n",
            "[Fooocus] Preparing Fooocus text #5 ...\n",
            "[Prompt Expansion] highly detailed face, bright colors, sunny, friendly, glowing, vivid, beautiful, surreal, pretty, aesthetic, dramatic, intricate, highly detail, professional, cheerful, elegant, best, colorful, light, saturated, amazing, flowing, magic, strong, romantic, complex, artistic, color, atmosphere, iconic, fine, very inspirational, perfect, epic, cinematic\n",
            "[Fooocus] Preparing Fooocus text #6 ...\n",
            "[Prompt Expansion] highly detailed face, bright colors, sunny, friendly, glowing, vivid, beautiful, surreal, pretty, aesthetic, dramatic, intricate, highly detail, professional, cheerful, elegant, best, colorful, light, saturated, amazing, flowing, magic, strong, romantic, complex, artistic, color, atmosphere, iconic, fine, very inspirational, perfect, epic, cinematic\n",
            "[Fooocus] Preparing Fooocus text #7 ...\n",
            "[Prompt Expansion] highly detailed face, bright colors, sunny, friendly, glowing, vivid, beautiful, surreal, pretty, aesthetic, dramatic, intricate, highly detail, professional, cheerful, elegant, best, colorful, light, saturated, amazing, flowing, magic, strong, romantic, complex, artistic, color, atmosphere, iconic, fine, very inspirational, perfect, epic, cinematic\n",
            "[Fooocus] Preparing Fooocus text #8 ...\n",
            "[Prompt Expansion] highly detailed face, bright colors, sunny, friendly, glowing, vivid, beautiful, surreal, pretty, aesthetic, dramatic, intricate, highly detail, professional, cheerful, elegant, best, colorful, light, saturated, amazing, flowing, magic, strong, romantic, complex, artistic, color, atmosphere, iconic, fine, very inspirational, perfect, epic, cinematic\n",
            "[Fooocus] Preparing Fooocus text #9 ...\n",
            "[Prompt Expansion] highly detailed face, bright colors, sunny, friendly, glowing, vivid, beautiful, surreal, pretty, aesthetic, dramatic, intricate, highly detail, professional, cheerful, elegant, best, colorful, light, saturated, amazing, flowing, magic, strong, romantic, complex, artistic, color, atmosphere, iconic, fine, very inspirational, perfect, epic, cinematic\n",
            "[Fooocus] Preparing Fooocus text #10 ...\n",
            "[Prompt Expansion] highly detailed face, bright colors, sunny, friendly, glowing, vivid, beautiful, surreal, pretty, aesthetic, dramatic, intricate, highly detail, professional, cheerful, elegant, best, colorful, light, saturated, amazing, flowing, magic, strong, romantic, complex, artistic, color, atmosphere, iconic, fine, very inspirational, perfect, epic, cinematic\n",
            "[Fooocus] Preparing Fooocus text #11 ...\n",
            "[Prompt Expansion] highly detailed face, bright colors, sunny, friendly, glowing, vivid, beautiful, surreal, pretty, aesthetic, dramatic, intricate, highly detail, professional, cheerful, elegant, best, colorful, light, saturated, amazing, flowing, magic, strong, romantic, complex, artistic, color, atmosphere, iconic, fine, very inspirational, perfect, epic, cinematic\n",
            "[Fooocus] Preparing Fooocus text #12 ...\n",
            "[Prompt Expansion] highly detailed face, bright colors, sunny, friendly, glowing, vivid, beautiful, surreal, pretty, aesthetic, dramatic, intricate, highly detail, professional, cheerful, elegant, best, colorful, light, saturated, amazing, flowing, magic, strong, romantic, complex, artistic, color, atmosphere, iconic, fine, very inspirational, perfect, epic, cinematic\n",
            "[Fooocus] Preparing Fooocus text #13 ...\n",
            "[Prompt Expansion] highly detailed face, bright colors, sunny, friendly, glowing, vivid, beautiful, surreal, pretty, aesthetic, dramatic, intricate, highly detail, professional, cheerful, elegant, best, colorful, light, saturated, amazing, flowing, magic, strong, romantic, complex, artistic, color, atmosphere, iconic, fine, very inspirational, perfect, epic, cinematic\n",
            "[Fooocus] Preparing Fooocus text #14 ...\n",
            "[Prompt Expansion] highly detailed face, bright colors, sunny, friendly, glowing, vivid, beautiful, surreal, pretty, aesthetic, dramatic, intricate, highly detail, professional, cheerful, elegant, best, colorful, light, saturated, amazing, flowing, magic, strong, romantic, complex, artistic, color, atmosphere, iconic, fine, very inspirational, perfect, epic, cinematic\n",
            "[Fooocus] Preparing Fooocus text #15 ...\n",
            "[Prompt Expansion] highly detailed face, bright colors, sunny, friendly, glowing, vivid, beautiful, surreal, pretty, aesthetic, dramatic, intricate, highly detail, professional, cheerful, elegant, best, colorful, light, saturated, amazing, flowing, magic, strong, romantic, complex, artistic, color, atmosphere, iconic, fine, very inspirational, perfect, epic, cinematic\n",
            "[Fooocus] Preparing Fooocus text #16 ...\n",
            "[Prompt Expansion] highly detailed face, bright colors, sunny, friendly, glowing, vivid, beautiful, surreal, pretty, aesthetic, dramatic, intricate, highly detail, professional, cheerful, elegant, best, colorful, light, saturated, amazing, flowing, magic, strong, romantic, complex, artistic, color, atmosphere, iconic, fine, very inspirational, perfect, epic, cinematic\n",
            "[Fooocus] Preparing Fooocus text #17 ...\n",
            "[Prompt Expansion] highly detailed face, bright colors, sunny, friendly, glowing, vivid, beautiful, surreal, pretty, aesthetic, dramatic, intricate, highly detail, professional, cheerful, elegant, best, colorful, light, saturated, amazing, flowing, magic, strong, romantic, complex, artistic, color, atmosphere, iconic, fine, very inspirational, perfect, epic, cinematic\n",
            "[Fooocus] Preparing Fooocus text #18 ...\n",
            "[Prompt Expansion] highly detailed face, bright colors, sunny, friendly, glowing, vivid, beautiful, surreal, pretty, aesthetic, dramatic, intricate, highly detail, professional, cheerful, elegant, best, colorful, light, saturated, amazing, flowing, magic, strong, romantic, complex, artistic, color, atmosphere, iconic, fine, very inspirational, perfect, epic, cinematic\n",
            "[Fooocus] Preparing Fooocus text #19 ...\n",
            "[Prompt Expansion] highly detailed face, bright colors, sunny, friendly, glowing, vivid, beautiful, surreal, pretty, aesthetic, dramatic, intricate, highly detail, professional, cheerful, elegant, best, colorful, light, saturated, amazing, flowing, magic, strong, romantic, complex, artistic, color, atmosphere, iconic, fine, very inspirational, perfect, epic, cinematic\n",
            "[Fooocus] Preparing Fooocus text #20 ...\n",
            "[Prompt Expansion] highly detailed face, bright colors, sunny, friendly, glowing, vivid, beautiful, surreal, pretty, aesthetic, dramatic, intricate, highly detail, professional, cheerful, elegant, best, colorful, light, saturated, amazing, flowing, magic, strong, romantic, complex, artistic, color, atmosphere, iconic, fine, very inspirational, perfect, epic, cinematic\n",
            "[Fooocus] Preparing Fooocus text #21 ...\n",
            "[Prompt Expansion] highly detailed face, bright colors, sunny, friendly, glowing, vivid, beautiful, surreal, pretty, aesthetic, dramatic, intricate, highly detail, professional, cheerful, elegant, best, colorful, light, saturated, amazing, flowing, magic, strong, romantic, complex, artistic, color, atmosphere, iconic, fine, very inspirational, perfect, epic, cinematic\n",
            "[Fooocus] Preparing Fooocus text #22 ...\n",
            "[Prompt Expansion] highly detailed face, bright colors, sunny, friendly, glowing, vivid, beautiful, surreal, pretty, aesthetic, dramatic, intricate, highly detail, professional, cheerful, elegant, best, colorful, light, saturated, amazing, flowing, magic, strong, romantic, complex, artistic, color, atmosphere, iconic, fine, very inspirational, perfect, epic, cinematic\n",
            "[Fooocus] Preparing Fooocus text #23 ...\n",
            "[Prompt Expansion] highly detailed face, bright colors, sunny, friendly, glowing, vivid, beautiful, surreal, pretty, aesthetic, dramatic, intricate, highly detail, professional, cheerful, elegant, best, colorful, light, saturated, amazing, flowing, magic, strong, romantic, complex, artistic, color, atmosphere, iconic, fine, very inspirational, perfect, epic, cinematic\n",
            "[Fooocus] Preparing Fooocus text #24 ...\n",
            "[Prompt Expansion] highly detailed face, bright colors, sunny, friendly, glowing, vivid, beautiful, surreal, pretty, aesthetic, dramatic, intricate, highly detail, professional, cheerful, elegant, best, colorful, light, saturated, amazing, flowing, magic, strong, romantic, complex, artistic, color, atmosphere, iconic, fine, very inspirational, perfect, epic, cinematic\n",
            "[Fooocus] Preparing Fooocus text #25 ...\n",
            "[Prompt Expansion] highly detailed face, bright colors, sunny, friendly, glowing, vivid, beautiful, surreal, pretty, aesthetic, dramatic, intricate, highly detail, professional, cheerful, elegant, best, colorful, light, saturated, amazing, flowing, magic, strong, romantic, complex, artistic, color, atmosphere, iconic, fine, very inspirational, perfect, epic, cinematic\n",
            "[Fooocus] Preparing Fooocus text #26 ...\n",
            "[Prompt Expansion] highly detailed face, bright colors, sunny, friendly, glowing, vivid, beautiful, surreal, pretty, aesthetic, dramatic, intricate, highly detail, professional, cheerful, elegant, best, colorful, light, saturated, amazing, flowing, magic, strong, romantic, complex, artistic, color, atmosphere, iconic, fine, very inspirational, perfect, epic, cinematic\n",
            "[Fooocus] Preparing Fooocus text #27 ...\n",
            "[Prompt Expansion] highly detailed face, bright colors, sunny, friendly, glowing, vivid, beautiful, surreal, pretty, aesthetic, dramatic, intricate, highly detail, professional, cheerful, elegant, best, colorful, light, saturated, amazing, flowing, magic, strong, romantic, complex, artistic, color, atmosphere, iconic, fine, very inspirational, perfect, epic, cinematic\n",
            "[Fooocus] Preparing Fooocus text #28 ...\n",
            "[Prompt Expansion] highly detailed face, bright colors, sunny, friendly, glowing, vivid, beautiful, surreal, pretty, aesthetic, dramatic, intricate, highly detail, professional, cheerful, elegant, best, colorful, light, saturated, amazing, flowing, magic, strong, romantic, complex, artistic, color, atmosphere, iconic, fine, very inspirational, perfect, epic, cinematic\n",
            "[Fooocus] Preparing Fooocus text #29 ...\n",
            "[Prompt Expansion] highly detailed face, bright colors, sunny, friendly, glowing, vivid, beautiful, surreal, pretty, aesthetic, dramatic, intricate, highly detail, professional, cheerful, elegant, best, colorful, light, saturated, amazing, flowing, magic, strong, romantic, complex, artistic, color, atmosphere, iconic, fine, very inspirational, perfect, epic, cinematic\n",
            "[Fooocus] Preparing Fooocus text #30 ...\n",
            "[Prompt Expansion] highly detailed face, bright colors, sunny, friendly, glowing, vivid, beautiful, surreal, pretty, aesthetic, dramatic, intricate, highly detail, professional, cheerful, elegant, best, colorful, light, saturated, amazing, flowing, magic, strong, romantic, complex, artistic, color, atmosphere, iconic, fine, very inspirational, perfect, epic, cinematic\n",
            "[Fooocus] Preparing Fooocus text #31 ...\n",
            "[Prompt Expansion] highly detailed face, bright colors, sunny, friendly, glowing, vivid, beautiful, surreal, pretty, aesthetic, dramatic, intricate, highly detail, professional, cheerful, elegant, best, colorful, light, saturated, amazing, flowing, magic, strong, romantic, complex, artistic, color, atmosphere, iconic, fine, very inspirational, perfect, epic, cinematic\n",
            "[Fooocus] Preparing Fooocus text #32 ...\n",
            "[Prompt Expansion] highly detailed face, bright colors, sunny, friendly, glowing, vivid, beautiful, surreal, pretty, aesthetic, dramatic, intricate, highly detail, professional, cheerful, elegant, best, colorful, light, saturated, amazing, flowing, magic, strong, romantic, complex, artistic, color, atmosphere, iconic, fine, very inspirational, perfect, epic, cinematic\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.12 seconds\n",
            "[Fooocus] Encoding positive #2 ...\n",
            "[Fooocus] Encoding positive #3 ...\n",
            "[Fooocus] Encoding positive #4 ...\n",
            "[Fooocus] Encoding positive #5 ...\n",
            "[Fooocus] Encoding positive #6 ...\n",
            "[Fooocus] Encoding positive #7 ...\n",
            "[Fooocus] Encoding positive #8 ...\n",
            "[Fooocus] Encoding positive #9 ...\n",
            "[Fooocus] Encoding positive #10 ...\n",
            "[Fooocus] Encoding positive #11 ...\n",
            "[Fooocus] Encoding positive #12 ...\n",
            "[Fooocus] Encoding positive #13 ...\n",
            "[Fooocus] Encoding positive #14 ...\n",
            "[Fooocus] Encoding positive #15 ...\n",
            "[Fooocus] Encoding positive #16 ...\n",
            "[Fooocus] Encoding positive #17 ...\n",
            "[Fooocus] Encoding positive #18 ...\n",
            "[Fooocus] Encoding positive #19 ...\n",
            "[Fooocus] Encoding positive #20 ...\n",
            "[Fooocus] Encoding positive #21 ...\n",
            "[Fooocus] Encoding positive #22 ...\n",
            "[Fooocus] Encoding positive #23 ...\n",
            "[Fooocus] Encoding positive #24 ...\n",
            "[Fooocus] Encoding positive #25 ...\n",
            "[Fooocus] Encoding positive #26 ...\n",
            "[Fooocus] Encoding positive #27 ...\n",
            "[Fooocus] Encoding positive #28 ...\n",
            "[Fooocus] Encoding positive #29 ...\n",
            "[Fooocus] Encoding positive #30 ...\n",
            "[Fooocus] Encoding positive #31 ...\n",
            "[Fooocus] Encoding positive #32 ...\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Encoding negative #2 ...\n",
            "[Fooocus] Encoding negative #3 ...\n",
            "[Fooocus] Encoding negative #4 ...\n",
            "[Fooocus] Encoding negative #5 ...\n",
            "[Fooocus] Encoding negative #6 ...\n",
            "[Fooocus] Encoding negative #7 ...\n",
            "[Fooocus] Encoding negative #8 ...\n",
            "[Fooocus] Encoding negative #9 ...\n",
            "[Fooocus] Encoding negative #10 ...\n",
            "[Fooocus] Encoding negative #11 ...\n",
            "[Fooocus] Encoding negative #12 ...\n",
            "[Fooocus] Encoding negative #13 ...\n",
            "[Fooocus] Encoding negative #14 ...\n",
            "[Fooocus] Encoding negative #15 ...\n",
            "[Fooocus] Encoding negative #16 ...\n",
            "[Fooocus] Encoding negative #17 ...\n",
            "[Fooocus] Encoding negative #18 ...\n",
            "[Fooocus] Encoding negative #19 ...\n",
            "[Fooocus] Encoding negative #20 ...\n",
            "[Fooocus] Encoding negative #21 ...\n",
            "[Fooocus] Encoding negative #22 ...\n",
            "[Fooocus] Encoding negative #23 ...\n",
            "[Fooocus] Encoding negative #24 ...\n",
            "[Fooocus] Encoding negative #25 ...\n",
            "[Fooocus] Encoding negative #26 ...\n",
            "[Fooocus] Encoding negative #27 ...\n",
            "[Fooocus] Encoding negative #28 ...\n",
            "[Fooocus] Encoding negative #29 ...\n",
            "[Fooocus] Encoding negative #30 ...\n",
            "[Fooocus] Encoding negative #31 ...\n",
            "[Fooocus] Encoding negative #32 ...\n",
            "[Fooocus] Image processing ...\n",
            "Upscaling image with shape (197, 197, 3) ...\n",
            "[Fooocus] VAE Inpaint encoding ...\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.47 seconds\n",
            "[Fooocus] VAE encoding ...\n",
            "Final resolution is (896, 1152), latent is (1024, 1024).\n",
            "Detected 1 faces\n",
            "Requested to load CLIPVisionModelWithProjection\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.54 seconds\n",
            "Requested to load Resampler\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.51 seconds\n",
            "Requested to load To_KV\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.26 seconds\n",
            "FreeU is enabled!\n",
            "[Parameters] Denoising Strength = 0.5\n",
            "[Parameters] Initial Latent shape: torch.Size([1, 4, 128, 128])\n",
            "Preparation time: 34.45 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/32 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 1.2431749105453491\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 3.79 seconds\n",
            " 10% 6/60 [00:07<01:05,  1.22s/it]\n",
            "User stopped\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 11.13 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 45.60 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 2.27 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.7 : 0.3\n",
            "[Parameters] Seed = 5583654085534942237\n",
            "[Parameters] CFG = 3\n",
            "[Fooocus] Downloading upscale models ...\n",
            "[Inpaint] Parameterized inpaint is disabled.\n",
            "[Fooocus] Downloading control models ...\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 24\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] highly detailed face, sharp focus, cinematic, fine light, dynamic composition, elegant, confident artistic colors, ambient background, classic, vivid, intricate, beautiful, stunning, creative, color, illuminated glowing, iconic, cozy, dramatic, deep aesthetic, highly varied, cool, cute, enhanced, famous, best, inspired, pretty, full, excellent, amazing, perfect\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.11 seconds\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Image processing ...\n",
            "Upscaling image with shape (197, 197, 3) ...\n",
            "[Fooocus] VAE Inpaint encoding ...\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.45 seconds\n",
            "[Fooocus] VAE encoding ...\n",
            "Final resolution is (896, 1152), latent is (1024, 1024).\n",
            "Detected 1 faces\n",
            "Requested to load CLIPVisionModelWithProjection\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.50 seconds\n",
            "Requested to load Resampler\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.51 seconds\n",
            "Requested to load To_KV\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.22 seconds\n",
            "FreeU is enabled!\n",
            "[Parameters] Denoising Strength = 0.5\n",
            "[Parameters] Initial Latent shape: torch.Size([1, 4, 128, 128])\n",
            "Preparation time: 10.42 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/1 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 1.2431749105453491\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 4.02 seconds\n",
            "100% 60/60 [01:00<00:00,  1.01s/it]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.25 seconds\n",
            "[Fooocus] Saving image 1/1 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-05-07/log.html\n",
            "Generating and saving time: 67.66 seconds\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 67.66 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 78.13 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 2.30 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.7 : 0.3\n",
            "[Parameters] Seed = 3429007983771703730\n",
            "[Parameters] CFG = 3\n",
            "[Fooocus] Downloading control models ...\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 24\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] RAW photo, ultra-realistic DSLR photo, full body of a gothic female model inspired by Billie Eilish, sitting on a vintage wooden chair in an old-fashioned bedroom, relaxed pose with hands on lap, introspective expression, soft and warm lighting, detailed, intricate, beautiful, highly detail, deep aesthetic, dramatic light, sunny, vibrant\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.13 seconds\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Image processing ...\n",
            "Detected 1 faces\n",
            "Requested to load CLIPVisionModelWithProjection\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.74 seconds\n",
            "Requested to load Resampler\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.47 seconds\n",
            "Requested to load To_KV\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.25 seconds\n",
            "FreeU is enabled!\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (1152, 896)\n",
            "Preparation time: 6.21 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/1 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 4.36 seconds\n",
            "100% 60/60 [01:00<00:00,  1.01s/it]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.25 seconds\n",
            "[Fooocus] Saving image 1/1 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-05-07/log.html\n",
            "Generating and saving time: 67.57 seconds\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 67.57 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 73.80 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 2.24 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.7 : 0.3\n",
            "[Parameters] Seed = 2643854164267254501\n",
            "[Parameters] CFG = 3\n",
            "[Fooocus] Downloading upscale models ...\n",
            "[Inpaint] Parameterized inpaint is disabled.\n",
            "[Fooocus] Downloading control models ...\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 24\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] highly detailed face, sharp focus, cinematic, fine composition, dynamic light, elegant, intricate, highly detail, inspired, still, background, professional, designed, vivid colors, ambient, sublime, magical, full color, expressive, perfect, deep rich, striking, complex, exciting, new, creative, awesome, atmosphere, novel, romantic, fancy, beautiful, epic\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.12 seconds\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Image processing ...\n",
            "Upscaling image with shape (281, 281, 3) ...\n",
            "[Fooocus] VAE Inpaint encoding ...\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.48 seconds\n",
            "[Fooocus] VAE encoding ...\n",
            "Final resolution is (896, 1152), latent is (1024, 1024).\n",
            "Detected 1 faces\n",
            "Requested to load CLIPVisionModelWithProjection\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.55 seconds\n",
            "Requested to load Resampler\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.45 seconds\n",
            "Requested to load To_KV\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.25 seconds\n",
            "FreeU is enabled!\n",
            "[Parameters] Denoising Strength = 0.5\n",
            "[Parameters] Initial Latent shape: torch.Size([1, 4, 128, 128])\n",
            "Preparation time: 11.26 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/1 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 1.2431749105453491\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 4.58 seconds\n",
            "100% 60/60 [01:01<00:00,  1.02s/it]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.27 seconds\n",
            "[Fooocus] Saving image 1/1 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-05-07/log.html\n",
            "Generating and saving time: 68.62 seconds\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 68.62 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 79.90 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 2.33 seconds\n"
          ]
        }
      ],
      "source": [
        "!pip install pygit2==1.15.1\n",
        "%cd /content\n",
        "!git clone https://github.com/lllyasviel/Fooocus.git\n",
        "%cd /content/Fooocus\n",
        "!python entry_with_update.py --share --always-high-vram\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}